{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea86941-c4ed-44fc-b39a-e1aa4c01c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes - visualisations for report?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c4313-89ae-498a-b829-8ad29c17cc95",
   "metadata": {},
   "source": [
    "## RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da01934-a22e-4c84-8535-5593065b5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Immune', 0), ('Other', 1), ('Stromal', 2), ('Tumour', 3)]\n",
      "\n",
      "ðŸ§ª Running evaluations on test set: test0\n",
      "â–¶ï¸  Evaluating baseline (no blur, no noise)...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=7, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=9, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=1...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=3...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=5...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=10...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=20...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=19, noise=30...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "\n",
      "ðŸ§ª Running evaluations on test set: test1\n",
      "â–¶ï¸  Evaluating baseline (no blur, no noise)...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=0, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=1, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=3, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n",
      "â–¶ï¸  Evaluating blur=5, noise=0...\n",
      "   ðŸ”¹ Model: base\n",
      "   ðŸ”¹ Model: pca\n",
      "   ðŸ”¹ Model: hog\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import shiny_data\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# suppress warnings for results\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "Xmat_train, Xmat_val, Xmat_tests_0, Xmat_tests_1, Xmat_tests_2, y_train_enc, y_val_enc, y_tests_enc_0, y_tests_enc_1, y_tests_enc_2 = shiny_data.load_split_images()\n",
    "\n",
    "def store_results(results, y_true, y_pred, probs=None, blur=0, noise=0, hog=False, pca=False, **extra_metrics):        \n",
    "    entry = {\n",
    "        \"blur_size\": blur,\n",
    "        \"noise_level\": noise,\n",
    "        \"HOG\": hog,\n",
    "        \"PCA\": pca,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "    }\n",
    "\n",
    "    f1_classes = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    precision_classes = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall_classes = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    label_map = {\n",
    "        0: \"immune\",\n",
    "        1: \"other\",\n",
    "        2: \"stromal\",\n",
    "        3: \"tumour\"\n",
    "    }\n",
    "    \n",
    "    for i in range(4):\n",
    "        label = label_map[i]\n",
    "        entry[f\"f1_{label}\"] = f1_classes[i]\n",
    "        entry[f\"precision_{label}\"] = precision_classes[i]\n",
    "        entry[f\"recall_{label}\"] = recall_classes[i]\n",
    "    \n",
    "    if probs is not None:\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        entry[\"confidence_overall\"] = np.mean(confidences)\n",
    "        for cls in range(4):\n",
    "            label = label_map[cls]\n",
    "            cls_conf = confidences[y_pred == cls]\n",
    "            entry[f\"confidence_{label}_avg\"] = np.mean(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "            entry[f\"confidence_{label}_std\"] = np.std(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "    \n",
    "    total_preds = len(y_pred)\n",
    "    for cls in range(4):\n",
    "        label = label_map[cls]\n",
    "        entry[f\"count_pred_{label}\"] = np.sum(y_pred == cls)\n",
    "\n",
    "    # store actual and predicted labels and the confusion matrix as strings\n",
    "    entry[\"confusion_matrix\"] = str(confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3]).tolist())\n",
    "\n",
    "    entry.update(extra_metrics)\n",
    "    results.append(entry)\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        if img.shape[-1] == 3:\n",
    "            img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"L\")\n",
    "            img = np.array(img)\n",
    "        features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "    \n",
    "\n",
    "# preprocessing\n",
    "X_train_flat = Xmat_train.reshape(Xmat_train.shape[0], -1)\n",
    "X_val_flat = Xmat_val.reshape(Xmat_val.shape[0], -1)\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "X_train_hog = extract_hog_features(Xmat_train)\n",
    "\n",
    "# fitting models\n",
    "model_base = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_base.fit(X_train_flat, y_train_enc)\n",
    "\n",
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_pca.fit(X_train_pca, y_train_enc)\n",
    "\n",
    "model_hog = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_hog.fit(X_train_hog, y_train_enc)\n",
    "\n",
    "# helper functions, model map\n",
    "def evaluate_and_store(model, X, y_true, probs=True, **kwargs):\n",
    "    y_pred = model.predict(X)\n",
    "    y_probs = model.predict_proba(X) if probs else None\n",
    "    store_results(results, y_true, y_pred, probs=y_probs, **kwargs)\n",
    "\n",
    "models = {\n",
    "    \"base\": (model_base, lambda X: X.reshape(X.shape[0], -1), {}),\n",
    "    \"pca\": (model_pca, lambda X: pca.transform(X.reshape(X.shape[0], -1)), {\"pca\": True}),\n",
    "    \"hog\": (model_hog, extract_hog_features, {\"hog\": True}),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def run_all_variants(X_base, y_base):\n",
    "    blur_levels = [0, 1, 3, 5, 7, 9, 19]\n",
    "    noise_levels = [0, 1, 3, 5, 10, 20, 30]\n",
    "\n",
    "    # Unmodified input (baseline)\n",
    "    print(\"â–¶ï¸  Evaluating baseline (no blur, no noise)...\")\n",
    "    for name, (model, transform, flags) in models.items():\n",
    "        print(f\"   ðŸ”¹ Model: {name}\")\n",
    "        X_trans = transform(X_base)\n",
    "        evaluate_and_store(model, X_trans, y_base, **flags)\n",
    "\n",
    "    # Blur only\n",
    "    for blur in blur_levels:\n",
    "        print(f\"â–¶ï¸  Evaluating blur={blur}, noise=0...\")\n",
    "        X_blur = shiny_data.apply_blur(X_base, blur)\n",
    "        for name, (model, transform, flags) in models.items():\n",
    "            print(f\"   ðŸ”¹ Model: {name}\")\n",
    "            X_trans = transform(X_blur)\n",
    "            evaluate_and_store(model, X_trans, y_base, blur=blur, **flags)\n",
    "\n",
    "    # Noise only\n",
    "    for noise in noise_levels:\n",
    "        print(f\"â–¶ï¸  Evaluating blur=0, noise={noise}...\")\n",
    "        np.random.seed(3888 + noise)\n",
    "        X_noisy = shiny_data.apply_noise(X_base, std=noise)\n",
    "        for name, (model, transform, flags) in models.items():\n",
    "            print(f\"   ðŸ”¹ Model: {name}\")\n",
    "            X_trans = transform(X_noisy)\n",
    "            evaluate_and_store(model, X_trans, y_base, noise=noise, **flags)\n",
    "\n",
    "    # Blur + noise \n",
    "    for blur in blur_levels:\n",
    "        for noise in noise_levels:\n",
    "            print(f\"â–¶ï¸  Evaluating blur={blur}, noise={noise}...\")\n",
    "            np.random.seed(10000 + blur * 100 + noise)\n",
    "            X_blur = shiny_data.apply_blur(X_base, blur)\n",
    "            X_combo = shiny_data.apply_noise(X_blur, std=noise)\n",
    "            for name, (model, transform, flags) in models.items():\n",
    "                print(f\"   ðŸ”¹ Model: {name}\")\n",
    "                X_trans = transform(X_combo)\n",
    "                evaluate_and_store(model, X_trans, y_base, blur=blur, noise=noise, **flags)\n",
    "\n",
    "test_sets = [\n",
    "    (\"test0\", Xmat_tests_0, y_tests_enc_0),\n",
    "    (\"test1\", Xmat_tests_1, y_tests_enc_1),\n",
    "    (\"test2\", Xmat_tests_2, y_tests_enc_2),\n",
    "]\n",
    "\n",
    "for name, X, y in test_sets:\n",
    "    print(f\"\\nðŸ§ª Running evaluations on test set: {name}\")\n",
    "    run_all_variants(X, y)\n",
    "\n",
    "pd.DataFrame(results).to_csv(\"rf_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b8ef6-b3b0-49c5-887e-aac025eea626",
   "metadata": {},
   "source": [
    "# Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2063ed4-166c-4293-8692-b2f33f7edb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tumour images loaded\n",
      "Immune images loaded\n",
      "Stromal images loaded\n",
      "Other images loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import shiny_data\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# suppress warnings for results\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# 0 Immune, 1 Other, 2 Stromal, 3 Tumour\n",
    "Xmat_train, Xmat_val, Xmat_tests_0, Xmat_tests_1, Xmat_tests_2, y_train_enc, y_val_enc, y_tests_enc_0, y_tests_enc_1, y_tests_enc_2 = shiny_data.load_split_images()\n",
    "\n",
    "def store_results(results, y_true, y_pred, probs=None, blur=0, noise=0, hog=False, pca=False, **extra_metrics):        \n",
    "    entry = {\n",
    "        \"blur_size\": blur,\n",
    "        \"noise_level\": noise,\n",
    "        \"HOG\": hog,\n",
    "        \"PCA\": pca,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "    }\n",
    "\n",
    "    f1_classes = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    precision_classes = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall_classes = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    label_map = {\n",
    "        0: \"immune\",\n",
    "        1: \"other\",\n",
    "        2: \"stromal\",\n",
    "        3: \"tumour\"\n",
    "    }\n",
    "    \n",
    "    for i in range(4):\n",
    "        label = label_map[i]\n",
    "        entry[f\"f1_{label}\"] = f1_classes[i]\n",
    "        entry[f\"precision_{label}\"] = precision_classes[i]\n",
    "        entry[f\"recall_{label}\"] = recall_classes[i]\n",
    "    \n",
    "    if probs is not None:\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        entry[\"confidence_overall\"] = np.mean(confidences)\n",
    "        for cls in range(4):\n",
    "            label = label_map[cls]\n",
    "            cls_conf = confidences[y_pred == cls]\n",
    "            entry[f\"confidence_{label}_avg\"] = np.mean(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "            entry[f\"confidence_{label}_std\"] = np.std(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "    \n",
    "    total_preds = len(y_pred)\n",
    "    for cls in range(4):\n",
    "        label = label_map[cls]\n",
    "        entry[f\"count_pred_{label}\"] = np.sum(y_pred == cls)\n",
    "\n",
    "    # store actual and predicted labels and the confusion matrix as strings\n",
    "    entry[\"confusion_matrix\"] = str(confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3]).tolist())\n",
    "\n",
    "    entry.update(extra_metrics)\n",
    "    results.append(entry)\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        if img.shape[-1] == 3:\n",
    "            img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"L\")\n",
    "            img = np.array(img)\n",
    "        features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "X_train_flat = Xmat_train.reshape(Xmat_train.shape[0], -1)\n",
    "X_val_flat   = Xmat_val.reshape(Xmat_val.shape[0], -1)\n",
    "X_test_flat  = Xmat_test.reshape(Xmat_test.shape[0], -1)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "\n",
    "# hog featues\n",
    "X_train_hog = extract_hog_features(Xmat_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03289a-aa79-4c95-97db-4081747e28d2",
   "metadata": {},
   "source": [
    "## Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27f735-ce62-4168-a8ff-c4a0071d8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# baseline model\n",
    "model_base = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_base.fit(X_train_flat, y_train_enc)\n",
    "X_test_flat = Xmat_test.reshape(Xmat_test.shape[0], -1)\n",
    "y_pred = model_base.predict(X_test_flat)\n",
    "probs = model_base.predict_proba(X_test_flat)\n",
    "store_results(results, y_test_enc, y_pred, probs=probs)\n",
    "\n",
    "# baseline PCA model\n",
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_pca.fit(X_train_pca, y_train_enc)\n",
    "X_test_pca = pca.transform(X_test_flat)\n",
    "y_pred = model_pca.predict(X_test_pca)\n",
    "y_probs = model_pca.predict_proba(X_test_pca)\n",
    "store_results(results, y_test_enc, y_pred, probs=y_probs)\n",
    "\n",
    "# HOG baseline model\n",
    "model_hog = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_hog.fit(X_train_hog, y_train_enc)\n",
    "X_test_hog = extract_hog_features(Xmat_test)\n",
    "y_pred = model_hog.predict(X_test_hog)\n",
    "probs = model_hog.predict_proba(X_test_hog)\n",
    "store_results(results, y_test_enc, y_pred, probs=probs, hog=True)\n",
    "\n",
    "# blur\n",
    "for radius in [0, 1, 3, 5, 7, 9, 19]:\n",
    "    X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "    X_test_flat = X_blur.reshape(X_blur.shape[0], -1)\n",
    "    y_pred = model_base.predict(X_test_flat)\n",
    "    probs = model_base.predict_proba(X_test_flat)\n",
    "    store_results(results, y_test_enc, y_pred, probs=probs, blur=radius)\n",
    "\n",
    "    X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "    X_test_flat = X_blur.reshape(X_blur.shape[0], -1)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    y_pred = model_pca.predict(X_test_pca)\n",
    "    y_probs = model_pca.predict_proba(X_test_pca)\n",
    "    store_results(results, y_test_enc, y_pred, blur=radius, probs=y_probs)\n",
    "\n",
    "    X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "    X_test_hog = extract_hog_features(X_blur)\n",
    "    y_pred = model_hog.predict(X_test_hog)\n",
    "    probs = model_hog.predict_proba(X_test_hog)\n",
    "    store_results(results, y_test_enc, y_pred, probs=probs, blur=radius, hog=True)\n",
    "\n",
    "# noise\n",
    "for noise_std in [0, 1, 3, 5, 10, 20, 30]:\n",
    "    np.random.seed(3888 + noise_std)\n",
    "    X_noisy = shiny_data.apply_noise(Xmat_test, std=noise_std)\n",
    "    X_test_flat = X_noisy.reshape(X_noisy.shape[0], -1)\n",
    "    y_pred = model_base.predict(X_test_flat)\n",
    "    probs = model_base.predict_proba(X_test_flat)\n",
    "    store_results(results, y_test_enc, y_pred, probs=probs, noise=noise_std)\n",
    "\n",
    "    np.random.seed(3888 + noise_std)  # set seed globally\n",
    "    X_noisy = shiny_data.apply_noise(Xmat_test, std=noise_std)  # no seed param\n",
    "    X_test_flat = X_noisy.reshape(X_noisy.shape[0], -1)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    y_pred = model_pca.predict(X_test_pca)\n",
    "    y_probs = model_pca.predict_proba(X_test_pca)\n",
    "    store_results(results, y_test_enc, y_pred, noise=noise_std, probs=y_probs)\n",
    "\n",
    "    np.random.seed(3888 + noise_std)\n",
    "    X_noisy = shiny_data.apply_noise(Xmat_test, std=noise_std)\n",
    "    X_test_hog = extract_hog_features(X_noisy)\n",
    "    y_pred = model_hog.predict(X_test_hog)\n",
    "    probs = model_hog.predict_proba(X_test_hog)\n",
    "    store_results(results, y_test_enc, y_pred, probs=probs, noise=noise_std, hog=True)\n",
    "\n",
    "# blur and noise\n",
    "for radius in [0, 1, 3, 5, 7, 9, 19]:\n",
    "    for noise_std in [0, 1, 3, 5, 10, 20, 30]:\n",
    "        np.random.seed(10000 + radius * 100 + noise_std)\n",
    "        X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "        X_combo = shiny_data.apply_noise(X_blur, std=noise_std)\n",
    "        X_test_flat = X_combo.reshape(X_combo.shape[0], -1)\n",
    "        y_pred = model_base.predict(X_test_flat)\n",
    "        probs = model_base.predict_proba(X_test_flat)\n",
    "        store_results(results, y_test_enc, y_pred, probs=probs, blur=radius, noise=noise_std)\n",
    "\n",
    "        np.random.seed(10000 + radius * 100 + noise_std)  # set seed globally\n",
    "        X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "        X_combo = shiny_data.apply_noise(X_blur, std=noise_std)\n",
    "        X_test_flat = X_combo.reshape(X_combo.shape[0], -1)\n",
    "        X_test_pca = pca.transform(X_test_flat)\n",
    "        y_pred = model_pca.predict(X_test_pca)\n",
    "        y_probs = model_pca.predict_proba(X_test_pca)\n",
    "        store_results(results, y_test_enc, y_pred, blur=radius, noise=noise_std, probs=y_probs)\n",
    "\n",
    "        np.random.seed(10000 + radius * 100 + noise_std)\n",
    "        X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "        X_combo = shiny_data.apply_noise(X_blur, std=noise_std)\n",
    "        X_test_hog = extract_hog_features(X_combo)\n",
    "        y_pred = model_hog.predict(X_test_hog)\n",
    "        probs = model_hog.predict_proba(X_test_hog)\n",
    "        store_results(results, y_test_enc, y_pred, probs=probs, blur=radius, noise=noise_std, hog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7934a66-bd16-47ac-b6e3-24cd7c740c26",
   "metadata": {},
   "source": [
    "## PCA Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10876172-15fe-440d-865c-8aeb3012de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== After Augmentations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hog</th>\n",
       "      <th>pca</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_class_0</th>\n",
       "      <th>f1_class_1</th>\n",
       "      <th>f1_class_2</th>\n",
       "      <th>f1_class_3</th>\n",
       "      <th>avg_conf</th>\n",
       "      <th>avg_conf_class_0</th>\n",
       "      <th>avg_conf_class_1</th>\n",
       "      <th>avg_conf_class_2</th>\n",
       "      <th>avg_conf_class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.519056</td>\n",
       "      <td>0.522985</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.602448</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>0.505759</td>\n",
       "      <td>0.641416</td>\n",
       "      <td>0.421730</td>\n",
       "      <td>0.365404</td>\n",
       "      <td>0.356304</td>\n",
       "      <td>0.480110</td>\n",
       "      <td>0.455003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53100</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.531346</td>\n",
       "      <td>0.53100</td>\n",
       "      <td>0.590017</td>\n",
       "      <td>0.341629</td>\n",
       "      <td>0.512233</td>\n",
       "      <td>0.636076</td>\n",
       "      <td>0.432130</td>\n",
       "      <td>0.365939</td>\n",
       "      <td>0.357240</td>\n",
       "      <td>0.485168</td>\n",
       "      <td>0.471721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50750</td>\n",
       "      <td>0.488253</td>\n",
       "      <td>0.541080</td>\n",
       "      <td>0.50750</td>\n",
       "      <td>0.488498</td>\n",
       "      <td>0.323564</td>\n",
       "      <td>0.530358</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>0.486962</td>\n",
       "      <td>0.354749</td>\n",
       "      <td>0.360694</td>\n",
       "      <td>0.526073</td>\n",
       "      <td>0.548417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44800</td>\n",
       "      <td>0.399494</td>\n",
       "      <td>0.530063</td>\n",
       "      <td>0.44800</td>\n",
       "      <td>0.215889</td>\n",
       "      <td>0.290578</td>\n",
       "      <td>0.531315</td>\n",
       "      <td>0.560195</td>\n",
       "      <td>0.553510</td>\n",
       "      <td>0.340443</td>\n",
       "      <td>0.372682</td>\n",
       "      <td>0.547533</td>\n",
       "      <td>0.621802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42700</td>\n",
       "      <td>0.359553</td>\n",
       "      <td>0.526073</td>\n",
       "      <td>0.42700</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>0.285176</td>\n",
       "      <td>0.527614</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.612982</td>\n",
       "      <td>0.328772</td>\n",
       "      <td>0.384392</td>\n",
       "      <td>0.580370</td>\n",
       "      <td>0.685282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41350</td>\n",
       "      <td>0.334670</td>\n",
       "      <td>0.494488</td>\n",
       "      <td>0.41350</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.259136</td>\n",
       "      <td>0.536374</td>\n",
       "      <td>0.525419</td>\n",
       "      <td>0.676308</td>\n",
       "      <td>0.332143</td>\n",
       "      <td>0.401703</td>\n",
       "      <td>0.619074</td>\n",
       "      <td>0.748943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hog    pca  Blur  Contrast  accuracy        f1  precision   recall  \\\n",
       "0   False  False     0      0.00   0.52975  0.519056   0.522985  0.52975   \n",
       "1   False  False     0      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "2   False  False     0      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "3   False  False     0      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "4   False  False     0      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "5   False  False     1      0.00   0.53100  0.519989   0.531346  0.53100   \n",
       "6   False  False     1      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "7   False  False     1      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "8   False  False     1      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "9   False  False     1      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "10  False  False     3      0.00   0.50750  0.488253   0.541080  0.50750   \n",
       "11  False  False     3      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "12  False  False     3      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "13  False  False     3      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "14  False  False     3      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "15  False  False     5      0.00   0.44800  0.399494   0.530063  0.44800   \n",
       "16  False  False     5      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "17  False  False     5      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "18  False  False     5      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "19  False  False     5      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "20  False  False     7      0.00   0.42700  0.359553   0.526073  0.42700   \n",
       "21  False  False     7      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "22  False  False     7      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "23  False  False     7      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "24  False  False     7      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "25  False  False    10      0.00   0.41350  0.334670   0.494488  0.41350   \n",
       "26  False  False    10      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "27  False  False    10      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "28  False  False    10      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "29  False  False    10      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "\n",
       "    f1_class_0  f1_class_1  f1_class_2  f1_class_3  avg_conf  \\\n",
       "0     0.602448    0.326599    0.505759    0.641416  0.421730   \n",
       "1     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "2     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "3     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "4     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "5     0.590017    0.341629    0.512233    0.636076  0.432130   \n",
       "6     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "7     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "8     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "9     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "10    0.488498    0.323564    0.530358    0.610592  0.486962   \n",
       "11    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "12    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "13    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "14    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "15    0.215889    0.290578    0.531315    0.560195  0.553510   \n",
       "16    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "17    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "18    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "19    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "20    0.083254    0.285176    0.527614    0.542169  0.612982   \n",
       "21    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "22    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "23    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "24    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "25    0.017751    0.259136    0.536374    0.525419  0.676308   \n",
       "26    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "27    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "28    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "29    0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "\n",
       "    avg_conf_class_0  avg_conf_class_1  avg_conf_class_2  avg_conf_class_3  \n",
       "0           0.365404          0.356304          0.480110          0.455003  \n",
       "1                NaN               NaN               NaN          0.420000  \n",
       "2                NaN               NaN               NaN          0.420000  \n",
       "3                NaN               NaN               NaN          0.420000  \n",
       "4                NaN               NaN               NaN          0.420000  \n",
       "5           0.365939          0.357240          0.485168          0.471721  \n",
       "6                NaN               NaN               NaN          0.420000  \n",
       "7                NaN               NaN               NaN          0.420000  \n",
       "8                NaN               NaN               NaN          0.420000  \n",
       "9                NaN               NaN               NaN          0.420000  \n",
       "10          0.354749          0.360694          0.526073          0.548417  \n",
       "11               NaN               NaN               NaN          0.420000  \n",
       "12               NaN               NaN               NaN          0.420000  \n",
       "13               NaN               NaN               NaN          0.420000  \n",
       "14               NaN               NaN               NaN          0.420000  \n",
       "15          0.340443          0.372682          0.547533          0.621802  \n",
       "16               NaN               NaN               NaN          0.420000  \n",
       "17               NaN               NaN               NaN          0.420000  \n",
       "18               NaN               NaN               NaN          0.420000  \n",
       "19               NaN               NaN               NaN          0.420000  \n",
       "20          0.328772          0.384392          0.580370          0.685282  \n",
       "21               NaN               NaN               NaN          0.420000  \n",
       "22               NaN               NaN               NaN          0.420000  \n",
       "23               NaN               NaN               NaN          0.420000  \n",
       "24               NaN               NaN               NaN          0.420000  \n",
       "25          0.332143          0.401703          0.619074          0.748943  \n",
       "26               NaN               NaN               NaN          0.420000  \n",
       "27               NaN               NaN               NaN          0.420000  \n",
       "28               NaN               NaN               NaN          0.420000  \n",
       "29               NaN               NaN               NaN          0.420000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_pca.fit(X_train_pca, y_train_enc)\n",
    "\n",
    "# baseline\n",
    "X_test_pca = pca.transform(X_test_flat)\n",
    "y_pred = model_pca.predict(X_test_pca)\n",
    "y_probs = model_pca.predict_proba(X_test_pca)\n",
    "store_results(results, y_test_enc, y_pred, probs=y_probs)\n",
    "\n",
    "for radius in [1, 3, 5, 7, 9, 19]: # blur\n",
    "    X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "    X_test_flat = X_blur.reshape(X_blur.shape[0], -1)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    y_pred = model_pca.predict(X_test_pca)\n",
    "    y_probs = model_pca.predict_proba(X_test_pca)\n",
    "    store_results(results, y_test_enc, y_pred, blur=radius, probs=y_probs)\n",
    "\n",
    "for noise_std in [1, 3, 5, 10, 20, 30]:\n",
    "    np.random.seed(3888 + noise_std)  # set seed globally\n",
    "    X_noisy = shiny_data.apply_noise(Xmat_test, std=noise_std)  # no seed param\n",
    "    X_test_flat = X_noisy.reshape(X_noisy.shape[0], -1)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    y_pred = model_pca.predict(X_test_pca)\n",
    "    y_probs = model_pca.predict_proba(X_test_pca)\n",
    "    store_results(results, y_test_enc, y_pred, noise=noise_std, probs=y_probs)\n",
    "\n",
    "for radius in [1, 3, 5, 7, 9, 19]:\n",
    "    for noise_std in [1, 3, 5, 10, 20, 30]:\n",
    "        np.random.seed(10000 + radius * 100 + noise_std)  # set seed globally\n",
    "        X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "        X_combo = shiny_data.apply_noise(X_blur, std=noise_std)\n",
    "        X_test_flat = X_combo.reshape(X_combo.shape[0], -1)\n",
    "        X_test_pca = pca.transform(X_test_flat)\n",
    "        y_pred = model_pca.predict(X_test_pca)\n",
    "        y_probs = model_pca.predict_proba(X_test_pca)\n",
    "        store_results(results, y_test_enc, y_pred, blur=radius, noise=noise_std, probs=y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266d4d2-1727-4ac8-bda8-3564f017da99",
   "metadata": {},
   "source": [
    "## HOG Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d956f9-0c01-4c3e-b805-55d861c86531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== After Augmentations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hog</th>\n",
       "      <th>pca</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_class_0</th>\n",
       "      <th>f1_class_1</th>\n",
       "      <th>f1_class_2</th>\n",
       "      <th>f1_class_3</th>\n",
       "      <th>avg_conf</th>\n",
       "      <th>avg_conf_class_0</th>\n",
       "      <th>avg_conf_class_1</th>\n",
       "      <th>avg_conf_class_2</th>\n",
       "      <th>avg_conf_class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.519056</td>\n",
       "      <td>0.522985</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.602448</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>0.505759</td>\n",
       "      <td>0.641416</td>\n",
       "      <td>0.421730</td>\n",
       "      <td>0.365404</td>\n",
       "      <td>0.356304</td>\n",
       "      <td>0.480110</td>\n",
       "      <td>0.455003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27825</td>\n",
       "      <td>0.196837</td>\n",
       "      <td>0.227026</td>\n",
       "      <td>0.27825</td>\n",
       "      <td>0.402404</td>\n",
       "      <td>0.143590</td>\n",
       "      <td>0.241356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.363209</td>\n",
       "      <td>0.332603</td>\n",
       "      <td>0.339495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.26875</td>\n",
       "      <td>0.176411</td>\n",
       "      <td>0.224271</td>\n",
       "      <td>0.26875</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.174944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361403</td>\n",
       "      <td>0.366571</td>\n",
       "      <td>0.330893</td>\n",
       "      <td>0.335960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.26400</td>\n",
       "      <td>0.163683</td>\n",
       "      <td>0.216926</td>\n",
       "      <td>0.26400</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.103668</td>\n",
       "      <td>0.151062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364415</td>\n",
       "      <td>0.369563</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.333284</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.26350</td>\n",
       "      <td>0.162246</td>\n",
       "      <td>0.469811</td>\n",
       "      <td>0.26350</td>\n",
       "      <td>0.397871</td>\n",
       "      <td>0.090312</td>\n",
       "      <td>0.158805</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.365582</td>\n",
       "      <td>0.370881</td>\n",
       "      <td>0.323486</td>\n",
       "      <td>0.331250</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.153847</td>\n",
       "      <td>0.211862</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.398419</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.122285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367570</td>\n",
       "      <td>0.372339</td>\n",
       "      <td>0.325245</td>\n",
       "      <td>0.333374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hog    pca  Blur  Contrast  accuracy        f1  precision   recall  \\\n",
       "0   False  False     0      0.00   0.52975  0.519056   0.522985  0.52975   \n",
       "1   False  False     0      1.25   0.25000  0.100000   0.062500  0.25000   \n",
       "2   False  False     0      1.50   0.25000  0.100000   0.062500  0.25000   \n",
       "3   False  False     0      1.75   0.25000  0.100000   0.062500  0.25000   \n",
       "4   False  False     0      2.00   0.25000  0.100000   0.062500  0.25000   \n",
       "..    ...    ...   ...       ...       ...       ...        ...      ...   \n",
       "85   True  False    10      0.00   0.27825  0.196837   0.227026  0.27825   \n",
       "86   True  False    10      1.25   0.26875  0.176411   0.224271  0.26875   \n",
       "87   True  False    10      1.50   0.26400  0.163683   0.216926  0.26400   \n",
       "88   True  False    10      1.75   0.26350  0.162246   0.469811  0.26350   \n",
       "89   True  False    10      2.00   0.26000  0.153847   0.211862  0.26000   \n",
       "\n",
       "    f1_class_0  f1_class_1  f1_class_2  f1_class_3  avg_conf  \\\n",
       "0     0.602448    0.326599    0.505759    0.641416  0.421730   \n",
       "1     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "2     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "3     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "4     0.000000    0.000000    0.000000    0.400000  0.420000   \n",
       "..         ...         ...         ...         ...       ...   \n",
       "85    0.402404    0.143590    0.241356    0.000000  0.357600   \n",
       "86    0.399451    0.131250    0.174944    0.000000  0.361403   \n",
       "87    0.400000    0.103668    0.151062    0.000000  0.364415   \n",
       "88    0.397871    0.090312    0.158805    0.001998  0.365582   \n",
       "89    0.398419    0.094684    0.122285    0.000000  0.367570   \n",
       "\n",
       "    avg_conf_class_0  avg_conf_class_1  avg_conf_class_2  avg_conf_class_3  \n",
       "0           0.365404          0.356304          0.480110          0.455003  \n",
       "1                NaN               NaN               NaN          0.420000  \n",
       "2                NaN               NaN               NaN          0.420000  \n",
       "3                NaN               NaN               NaN          0.420000  \n",
       "4                NaN               NaN               NaN          0.420000  \n",
       "..               ...               ...               ...               ...  \n",
       "85          0.363209          0.332603          0.339495               NaN  \n",
       "86          0.366571          0.330893          0.335960               NaN  \n",
       "87          0.369563          0.327205          0.333284               NaN  \n",
       "88          0.370881          0.323486          0.331250          0.290000  \n",
       "89          0.372339          0.325245          0.333374               NaN  \n",
       "\n",
       "[90 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_hog = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_hog.fit(X_train_hog, y_train_enc)\n",
    "\n",
    "# baseline\n",
    "X_test_hog = extract_hog_features(Xmat_test)\n",
    "y_pred = model_hog.predict(X_test_hog)\n",
    "probs = model_hog.predict_proba(X_test_hog)\n",
    "store_results(results, y_test_enc, y_pred, probs=probs, hog=True)\n",
    "\n",
    "# blur\n",
    "for radius in [1, 3, 5, 7, 9, 19]:\n",
    "    X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "    X_test_hog = extract_hog_features(X_blur)\n",
    "    y_pred = model_hog.predict(X_test_hog)\n",
    "    probs = model_hog.predict_proba(X_test_hog)\n",
    "    store_results(results, y_test_enc, y_pred, probs=probs, blur=radius, hog=True)\n",
    "\n",
    "# noise\n",
    "for noise_std in [1, 3, 5, 10, 20, 30]:\n",
    "    np.random.seed(3888 + noise_std)\n",
    "    X_noisy = shiny_data.apply_noise(Xmat_test, std=noise_std)\n",
    "    X_test_hog = extract_hog_features(X_noisy)\n",
    "    y_pred = model_hog.predict(X_test_hog)\n",
    "    probs = model_hog.predict_proba(X_test_hog)\n",
    "    store_results(results, y_test_enc, y_pred, probs=probs, noise=noise_std, hog=True)\n",
    "\n",
    "# blur and noise\n",
    "for radius in [1, 3, 5, 7, 9, 19]:\n",
    "    for noise_std in [1, 3, 5, 10, 20, 30]:\n",
    "        np.random.seed(10000 + radius * 100 + noise_std)\n",
    "        X_blur = shiny_data.apply_blur(Xmat_test, radius)\n",
    "        X_combo = shiny_data.apply_noise(X_blur, std=noise_std)\n",
    "        X_test_hog = extract_hog_features(X_combo)\n",
    "        y_pred = model_hog.predict(X_test_hog)\n",
    "        probs = model_hog.predict_proba(X_test_hog)\n",
    "        store_results(results, y_test_enc, y_pred, probs=probs, blur=radius, noise=noise_std, hog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "225d9db9-9bb8-4698-962a-3dd9f64d9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"model_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
