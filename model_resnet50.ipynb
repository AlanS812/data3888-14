{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c2ef70-6377-46d7-a5d5-3e647409034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fff558-b739-498f-ab22-4e38262374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/100\"\n",
    "\n",
    "# Get tumour file paths and shuffle\n",
    "tumour_files = []\n",
    "tumour_dirs = [\n",
    "    \"Invasive_Tumor\",\n",
    "    \"Prolif_Invasive_Tumor\",\n",
    "    \"T_Cell_and_Tumor_Hybrid\"\n",
    "]\n",
    "\n",
    "for dir_name in tumour_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        tumour_files.extend(files)\n",
    "\n",
    "random.shuffle(tumour_files)\n",
    "\n",
    "# Get immune file paths and shuffle\n",
    "immune_files = []\n",
    "immune_dirs = [\n",
    "    \"CD4+_T_Cells\", \"CD4+_T_Cells\", \n",
    "    \"CD8+_T_Cells\", \n",
    "    \"B_Cells\", \n",
    "    \"Mast_Cells\", \n",
    "    \"Macrophages_1\", \n",
    "    \"Macrophages_2\", \n",
    "    \"LAMP3+_DCs\",\n",
    "    \"IRF7+_DCs\"\n",
    "]\n",
    "\n",
    "for dir_name in immune_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        immune_files.extend(files)\n",
    "\n",
    "random.shuffle(immune_files)\n",
    "\n",
    "\n",
    "# Get stromal file paths and shuffle\n",
    "stromal_files = []\n",
    "stromal_dirs = [\n",
    "    \"Stromal\", \n",
    "    \"Stromal_and_T_Cell_Hybrid\", \n",
    "    \"Perivascular-Like\"\n",
    "]\n",
    "\n",
    "for dir_name in stromal_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        stromal_files.extend(files)\n",
    "\n",
    "random.shuffle(stromal_files)\n",
    "\n",
    "# Get other file paths and shuffle\n",
    "other_files = []\n",
    "other_dirs = [\n",
    "    \"Endothelial\",\n",
    "    \"Myoepi_ACTA2+\", \n",
    "    \"Myoepi_KRT15+\", \n",
    "    \"DCIS_1\", \n",
    "    \"DCIS_2\", \n",
    "]\n",
    "\n",
    "for dir_name in stromal_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        other_files.extend(files)\n",
    "\n",
    "random.shuffle(other_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ce502b-23f9-48ff-95d8-453f1252b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize(img_path, size=(224,224)):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(size)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90906d4-8da0-47a4-b5a6-b85a7b4f2363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumour loaded\n",
      "immune loaded\n",
      "stromal loaded\n",
      "other loaded\n"
     ]
    }
   ],
   "source": [
    "tumour_imgs = [load_resize(f) for f in tumour_files]\n",
    "print(\"tumour loaded\")\n",
    "\n",
    "immune_imgs = [load_resize(f) for f in immune_files]\n",
    "print(\"immune loaded\")\n",
    "\n",
    "stromal_imgs = [load_resize(f) for f in stromal_files]\n",
    "print(\"stromal loaded\")\n",
    "\n",
    "other_imgs = [load_resize(f) for f in other_files]\n",
    "print(\"other loaded\")\n",
    "\n",
    "# Train using 80% of data from each group\n",
    "'''\n",
    "tumour_train_ind = int(0.8 * len(tumour_imgs))\n",
    "tumour_test_ind = int(0.2 * len(tumour_imgs))\n",
    "\n",
    "immune_train_ind = int(0.8 * len(immune_imgs))\n",
    "immune_test_ind = int(0.2 * len(immune_imgs))\n",
    "\n",
    "stromal_train_ind = int(0.8 * len(stromal_imgs))\n",
    "stromal_test_ind = int(0.2 * len(stromal_imgs))\n",
    "\n",
    "other_train_ind = int(0.8 * len(other_imgs))\n",
    "other_test_ind = int(0.2 * len(other_imgs))\n",
    "'''\n",
    "\n",
    "tumour_train_ind = 5000\n",
    "tumour_test_ind = 6000\n",
    "\n",
    "immune_train_ind = 5000\n",
    "immune_test_ind = 6000\n",
    "\n",
    "stromal_train_ind = 5000\n",
    "stromal_test_ind = 6000\n",
    "\n",
    "other_train_ind = 5000\n",
    "other_test_ind = 6000\n",
    "\n",
    "imgs_train = immune_imgs[:immune_train_ind] + tumour_imgs[:tumour_train_ind] + stromal_imgs[:stromal_train_ind] + other_imgs[:other_train_ind]\n",
    "imgs_test = immune_imgs[immune_train_ind:immune_test_ind] + tumour_imgs[tumour_train_ind:tumour_test_ind] + stromal_imgs[stromal_train_ind:stromal_test_ind] + other_imgs[other_train_ind:other_test_ind]\n",
    "\n",
    "Xmat_train_og = np.stack(imgs_train, axis=0)\n",
    "Xmat_test = np.stack(imgs_test, axis=0)\n",
    "\n",
    "y_train = ['Immune'] * immune_train_ind + ['Tumour'] * tumour_train_ind + ['Stromal'] * stromal_train_ind + ['Other'] * other_train_ind\n",
    "y_test = ['Immune'] * immune_test_ind + ['Tumour'] * tumour_test_ind + ['Stromal'] * stromal_test_ind + ['Other'] * other_test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b984db-ba83-4a27-a685-69fce077f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blur(images, kernel_size):\n",
    "    return np.array([cv2.GaussianBlur(img, kernel_size, 0) for img in images])\n",
    "\n",
    "def apply_greyscale(images):\n",
    "    greyscale = []\n",
    "    for img in images:\n",
    "        pil_img = Image.fromarray(img)\n",
    "        grey = pil_img.convert(\"L\")\n",
    "        grey_3ch = grey.convert(\"RGB\")\n",
    "        greyscale.append(np.array(grey_3ch))\n",
    "    return np.array(greyscale)\n",
    "\n",
    "def adjust_contrast(images, factor=1.5):\n",
    "    adjusted = []\n",
    "    for img in images:\n",
    "        pil_img = Image.fromarray(img)\n",
    "        enhancer = ImageEnhance.Contrast(pil_img)\n",
    "        contrasted = enhancer.enhance(factor)\n",
    "        adjusted.append(np.array(contrasted))\n",
    "    return np.array(adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d994753b-e75e-41a3-9b80-5eaf4279467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338cbd41-b0a6-42ba-8dd5-ad8699c16cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        image = Image.fromarray((image * 255).astype('uint8'))  # Convert to PIL Image\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5036590c-ab81-4c41-ad21-6d287254dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = NumpyImageDataset(Xmat_train_og, y_train_enc, transform=transform)\n",
    "test_dataset = NumpyImageDataset(Xmat_test, y_test_enc, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb765ed5-738d-4473-9260-9f5c49decc38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0964, Accuracy: 0.4878\n",
      "Epoch 2, Loss: 1.0438, Accuracy: 0.5151\n",
      "Epoch 3, Loss: 1.0325, Accuracy: 0.5274\n",
      "Epoch 4, Loss: 1.0228, Accuracy: 0.5363\n",
      "Epoch 5, Loss: 1.0097, Accuracy: 0.5344\n",
      "Epoch 6, Loss: 1.0210, Accuracy: 0.5347\n",
      "Epoch 7, Loss: 1.0010, Accuracy: 0.5475\n",
      "Epoch 8, Loss: 1.0070, Accuracy: 0.5406\n",
      "Epoch 9, Loss: 1.0000, Accuracy: 0.5457\n",
      "Epoch 10, Loss: 0.9964, Accuracy: 0.5453\n"
     ]
    }
   ],
   "source": [
    "# Train model with no augmentations\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "num_epochs_og = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0b3838d-cb4b-4dd7-a11d-4c60d3f63da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 25.68%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHUCAYAAAANwniNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkfElEQVR4nO3deXhTVeLG8TdNkzRdoS2UFsqqIrtAURY3FBAYGHEZFEVBFmVQXBhHQccFHeUnjsiMCuoIdERR3HAYBbVuIKKyaN3YXEC2spSte5I29/dH2tCQtmkFki7fz/PkSe655yYnySn07Tn3XJNhGIYAAAAAAJUKC3UDAAAAAKC2IzgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AWhw0tPTZTKZtH79+lA3pdZo3bq1xo4dW+362dnZstlsfI6/k8vl0rx589SnTx/FxcXJbrerQ4cOmjZtmg4ePBjq5vl58MEHZTKZKr1t3749pO379NNPZTKZ9MYbb4S0HQDqt/BQNwAAUPcsWrRITqdTkjR//nylpaWFuEV1R0FBgYYOHarVq1frxhtv1H333Se73a4vvvhC//jHP7R48WJlZGSoffv2oW6qn/fee09xcXF+5cnJySFoDQAEF8EJAFBjCxYsUNOmTdWqVSu98sormj17tux2e6ib5cflcslkMik8vPb8d3fHHXdo5cqVevXVV3XVVVd5y/v3768rr7xSZ599tq644gp9++23MpvNQWtXQUGBIiMjq6zTs2dPJSYmBqlFAFC7MFUPACqxevVqXXzxxYqJiVFkZKT69u2rd99916dOQUGB7rzzTrVp00YRERGKj49XWlqaXnnlFW+dX3/9VVdffbVSUlJks9mUlJSkiy++WJmZmVW+/vr163X11VerdevWstvtat26tUaNGqXffvvNp17Z1MNPPvlEf/7zn5WYmKiEhARdfvnl2rNnj09dl8ulu+66S82aNVNkZKTOPfdcrV27tkafy1dffaUffvhB1113nSZOnKijR4/qzTff9Kvndrv11FNP6ayzzpLdblejRo3Uu3dvLVu2zKfe4sWL1adPH0VHRys6OlpnnXWW5s+f791f2TTCCy+8UBdeeKF3u2y61qJFi/SXv/xFzZs3l81m088//6wDBw5o8uTJ6tixo6Kjo9W0aVNddNFF+uyzz/ye1+Fw6KGHHlKHDh0UERGhhIQE9e/fX2vWrJEkXXzxxTrzzDNlGIbPcYZh6LTTTtMf/vCHSj+7vXv3asGCBbrkkkt8QlOZM844Q3fffbd+/PFHvf3225KkESNGqFWrVnK73X71zznnHPXo0cOnDXPnzvV+5o0bN9aVV16pX3/91e+z69y5s1atWqW+ffsqMjJS48aNq7Td1bV9+3aZTCbNmjVLjzzyiFq2bKmIiAilpaXpo48+8qtfnZ8xSdq9e7duvPFGpaamymq1KiUlRVdeeaX27dvnU8/lcunee+9VSkqKYmNjNWDAAG3ZssWnzjfffKNhw4apadOmstlsSklJ0R/+8Aft2rXrhN8/gPqN4AQAFVi5cqUuuugiHT16VPPnz9crr7yimJgYDR8+XEuWLPHWmzp1qubNm6dbb71V7733nhYtWqQ//elPPuepDB06VBs2bNCsWbOUkZGhefPmqXv37jpy5EiVbdi+fbvat2+vOXPm6P3339djjz2mrKws9erVS9nZ2X71J0yYIIvFosWLF2vWrFn69NNPNXr0aJ86EydO1D/+8Q9df/31+u9//6srrrhCl19+uQ4fPlztz6Ys1IwbN05XX321IiMjfYJOmbFjx+q2225Tr169tGTJEr366qv64x//6HM+zP33369rr71WKSkpSk9P19KlSzVmzBi/cFgT06dP144dO/Tss8/qf//7n5o2bapDhw5Jkh544AG9++67Wrhwodq2basLL7xQn376qffY4uJiDRkyRA8//LCGDRumpUuXKj09XX379tWOHTskSbfddpu2bNniFwRWrFihX375RTfffHOlbfvkk09UXFysESNGVFqnbF9GRoYkz+e8Y8cOffzxxz71Nm/erLVr1+qGG27wlt100026/fbbNWDAAL399tuaO3eufvzxR/Xt29cvZGRlZWn06NG65pprtHz5ck2ePLnSNpUpKSlRcXGxz62kpMSv3tNPP6333ntPc+bM0UsvvaSwsDANGTJEX3zxhbdOdX/Gdu/erV69emnp0qWaOnWqVqxYoTlz5iguLs6v395zzz367bff9MILL+j555/XTz/9pOHDh3vbmJ+fr4EDB2rfvn165plnlJGRoTlz5qhly5bKzc0N+P4BNHAGADQwCxcuNCQZ69atq7RO7969jaZNmxq5ubnesuLiYqNz585GixYtDLfbbRiGYXTu3NkYMWJEpc+TnZ1tSDLmzJlzwu0uLi428vLyjKioKOOf//yn3/uZPHmyT/1Zs2YZkoysrCzDMAxj06ZNhiTjjjvu8Kn38ssvG5KMMWPGBGxDfn6+ERsba/Tu3dtbNmbMGMNkMhk///yzt2zVqlWGJOPee++t9Ll+/fVXw2w2G9dee22Vr9mqVasK23bBBRcYF1xwgXf7k08+MSQZ559/fsD3UVxcbLhcLuPiiy82LrvsMm/5iy++aEgy/v3vf1d6bElJidG2bVvj0ksv9SkfMmSI0a5dO2/fqMj//d//GZKM9957r9I6hYWFhiRjyJAhhmEYhsvlMpKSkoxrrrnGp95dd91lWK1WIzs72zAMw/jiiy8MScYTTzzhU2/nzp2G3W437rrrLm/ZBRdcYEgyPvroo0rbUd4DDzxgSKrw1q5dO2+9bdu2GZKMlJQUo7Cw0Fuek5NjxMfHGwMGDPCWVfdnbNy4cYbFYjE2btxYafvKvvuhQ4f6lL/22muGJOOLL74wDMMw1q9fb0gy3n777Wq9bwAojxEnADhOfn6+vvrqK1155ZWKjo72lpvNZl133XXatWuXd/rP2WefrRUrVmjatGn69NNPVVhY6PNc8fHxateunR5//HHNnj1b33zzTYVTriqSl5enu+++W6eddprCw8MVHh6u6Oho5efna9OmTX71//jHP/psd+3aVZK8ozeffPKJJOnaa6/1qTdy5MhqnwP02muvKScnx2da17hx42QYhhYuXOgtW7FihSRVOfqSkZGhkpKSKuv8HldccUWF5c8++6x69OihiIgIhYeHy2Kx6KOPPvL5LFesWKGIiIgqp62FhYXplltu0TvvvOMdhfrll1/03nvvafLkyTKZTCflfZQ9T3h4uEaPHq233npLR48eleQZ+Vm0aJEuvfRSJSQkSJLeeecdmUwmjR492mdEqFmzZurWrZvPyJokNW7cWBdddFGN2vThhx9q3bp1PreyKYXlXX755YqIiPBul40krVq1SiUlJTX6GVuxYoX69++vDh06BGxfoJ+B0047TY0bN9bdd9+tZ599Vhs3bqzR+wfQsBGcAOA4hw8flmEYFa4UlpKSIkneqXj/+te/dPfdd+vtt99W//79FR8frxEjRuinn36S5Pnl96OPPtIll1yiWbNmqUePHmrSpIluvfXWgFODrrnmGj399NOaMGGC3n//fa1du1br1q1TkyZN/AKaJO8v0GVsNpskeeuWtblZs2Y+9cLDw/2Orcz8+fMVERGhwYMH68iRIzpy5Ii6du2q1q1bKz093Tsl6sCBAzKbzX6vVd6BAwckSS1atKjWa1dXRd/b7Nmz9ec//1nnnHOO3nzzTX355Zdat26dBg8e7PNZHjhwQCkpKQoLq/q/x3Hjxslut+vZZ5+VJD3zzDOy2+0BzxNq2bKlJGnbtm2V1inbl5qa6vN6RUVFevXVVyVJ77//vrKysnym6e3bt0+GYSgpKUkWi8Xn9uWXX/pN7/w9K+F169ZNaWlpPrfOnTv71avoe2/WrJmcTqfy8vJq9DN24MCBaveRQD8DcXFxWrlypc466yzdc8896tSpk1JSUvTAAw/I5XJV6zUANFy1Z5khAKglGjdurLCwMGVlZfntK1tsoWxlsaioKM2YMUMzZszQvn37vKNPw4cP1+bNmyVJrVq18p4DtHXrVr322mt68MEH5XQ6vb94H+/o0aN655139MADD2jatGnecofD4T1fp6bKfqncu3evmjdv7i0vLi6u1rWDtm7dqtWrV0s6FgCO9/7772vo0KFq0qSJSkpKtHfv3kp/QW/SpIkkadeuXT4h4XgRERFyOBx+5dnZ2RWu8FbRiM9LL72kCy+8UPPmzfMpPz68NmnSRKtXr5bb7a4yPMXFxWnMmDF64YUXdOedd2rhwoW65ppr1KhRo0qPkTwr54WHh+vtt9/WpEmTKqxTNoIzcOBAb1nHjh119tlna+HChbrpppu0cOFCpaSkaNCgQd46iYmJMplM+uyzz7yBobzjy07WyFhF9u7dW2GZ1WpVdHS0wsPDq/0z1qRJk5O6cEOXLl306quvyjAMfffdd0pPT9dDDz0ku93u87MGAMdjxAkAjhMVFaVzzjlHb731ls9ohNvt1ksvvaQWLVrojDPO8DsuKSlJY8eO1ahRo7RlyxYVFBT41TnjjDP0t7/9TV26dNHXX39daRtMJpMMw/D7ZfeFF16o8GT86ihbge7ll1/2KX/ttddUXFwc8Piy8Pfvf/9bn3zyic9t+fLlslgsWrBggSRpyJAhkuQXVMobNGiQzGZzlXUkz6p63333nU/Z1q1b/VZLq4rJZPL7LL/77jufxQrK2l1UVKT09PSAz3nrrbcqOztbV155pY4cOaJbbrkl4DHNmjXTuHHj9P777/ssgFBm69ateuyxx9SpUye/BSRuuOEGffXVV1q9erX+97//acyYMT7LlQ8bNkyGYWj37t1+o0JpaWnq0qVLwPadLG+99ZaKioq827m5ufrf//6n8847T2azuUY/Y0OGDNEnn3xSo++7Okwmk7p166Ynn3xSjRo1qvLnEQAkRpwANGAff/yxzwpvZYYOHaqZM2dq4MCB6t+/v+68805ZrVbNnTtXP/zwg1555RXvX+vPOeccDRs2TF27dlXjxo21adMmLVq0SH369FFkZKS+++473XLLLfrTn/6k008/XVarVR9//LG+++67Kv+6HRsbq/PPP1+PP/64EhMT1bp1a61cuVLz588POKpRmQ4dOmj06NGaM2eOLBaLBgwYoB9++EH/+Mc/FBsbW+WxxcXFevHFF9WhQwdNmDChwjrDhw/XsmXLdODAAZ133nm67rrr9Pe//1379u3TsGHDZLPZ9M033ygyMlJTpkxR69atdc899+jhhx9WYWGhRo0apbi4OG3cuFHZ2dmaMWOGJOm6667T6NGjNXnyZF1xxRX67bffNGvWLO+IVXUMGzZMDz/8sB544AFdcMEF2rJlix566CG1adPGJzSOGjVKCxcu1KRJk7Rlyxb1799fbrdbX331lTp06KCrr77aW/eMM87Q4MGDtWLFCp177rnq1q1btdoye/ZsbdmyRaNHj9aqVas0fPhw2Ww2ffnll/rHP/6hmJgYvfnmm37XcBo1apSmTp2qUaNGyeFw+C3R3q9fP91444264YYbtH79ep1//vmKiopSVlaWVq9erS5duujPf/5ztT+zimzYsKHCC+B27NjRpw+ZzWYNHDhQU6dOldvt1mOPPaacnBzvdyqp2j9jDz30kFasWKHzzz9f99xzj7p06aIjR47ovffe09SpU3XmmWdWu/3vvPOO5s6dqxEjRqht27YyDENvvfWWjhw54jPCBwAVCt26FAAQGmWr0FV227Ztm2EYhvHZZ58ZF110kREVFWXY7Xajd+/exv/+9z+f55o2bZqRlpZmNG7c2LDZbEbbtm2NO+64w7vS2b59+4yxY8caZ555phEVFWVER0cbXbt2NZ588kmjuLi4ynbu2rXLuOKKK4zGjRsbMTExxuDBg40ffvjBb5W5ylYJLFtp7JNPPvGWORwO4y9/+YvRtGlTIyIiwujdu7fxxRdfVLpyXZm333474OqA7733ns+qbiUlJcaTTz5pdO7c2bBarUZcXJzRp08fv8/wxRdfNHr16mVEREQY0dHRRvfu3Y2FCxd697vdbmPWrFlG27ZtjYiICCMtLc34+OOPK11V7/XXX/drm8PhMO68806jefPmRkREhNGjRw/j7bffNsaMGWO0atXKp25hYaFx//33G6effrphtVqNhIQE46KLLjLWrFnj97zp6emGJOPVV1+t9HOpiNPpNJ555hnjnHPOMaKjow2bzWa0b9/euOuuu7x9pyLXXHONIcno169fpXUWLFhgnHPOOd5+265dO+P666831q9f761zwQUXGJ06dap2e6taVU+SkZGRYRjGsVX1HnvsMWPGjBlGixYtDKvVanTv3t14//33/Z63Oj9jhuFZGXDcuHFGs2bNDIvFYqSkpBgjR4409u3bZxhG5d99WXvK+tPmzZuNUaNGGe3atTPsdrsRFxdnnH322UZ6enq1PwsADZfJMI67gh8AAKiWK664Ql9++aW2b98ui8US6uaE3Pbt29WmTRs9/vjjuvPOO0PdHAA4qZiqBwBADTgcDn399ddau3atli5dqtmzZxOaAKABIDgBAFADWVlZ6tu3r2JjY3XTTTdpypQpoW4SACAImKoHAAAAAAGwHDkAAAAABEBwAgAAAIAACE4AAAAAEECDWxzC7XZrz549iomJ8V5cDwAAAEDDYxiGcnNzlZKSorCwqseUGlxw2rNnj1JTU0PdDAAAAAC1xM6dO9WiRYsq6zS44BQTEyPJ8+HExsaGuDX4vVwulz744AMNGjSI66fglKO/Idjocwg2+hyCqTb1t5ycHKWmpnozQlUaXHAqm54XGxtLcKrDXC6XIiMjFRsbG/IfONR/9DcEG30OwUafQzDVxv5WnVN4WBwCAAAAAAIgOAEAAABAAAQnAAAAAAigwZ3jBAAAANSUYRgqLi5WSUlJqJtS57lcLoWHh6uoqCgon6fFYpHZbD7h5yE4AQAAAFVwOp3KyspSQUFBqJtSLxiGoWbNmmnnzp1Bua6qyWRSixYtFB0dfULPQ3ACAAAAKuF2u7Vt2zaZzWalpKTIarUG5Zf9+sztdisvL0/R0dEBLzp7ogzD0IEDB7Rr1y6dfvrpJzTyRHACAAAAKuF0OuV2u5WamqrIyMhQN6decLvdcjqdioiIOOXBSZKaNGmi7du3y+VynVBwYnEIAAAAIIBg/IKPU+NkjRCGtAesWrVKw4cPV0pKikwmk95+++0q62dlZemaa65R+/btFRYWpttvvz0o7QQAAADQsIU0OOXn56tbt256+umnq1Xf4XCoSZMmuvfee9WtW7dT3DoAAAAA8AjpOU5DhgzRkCFDql2/devW+uc//ylJWrBgwalqFgAAAAD4qPeLQzgcDjkcDu92Tk6OJM/68S6XK1TNwgkq++74DhEM9DcEG30OwUafq5zL5ZJhGHK73XK73aFuTo3ccMMNOnLkiJYuXRrqpvgwDMN7H4zP1O12yzCMCheHqEmfr/fBaebMmZoxY4Zf+QcffBDylVEMQyoxpHDONfzdMjIyQt0ENCD0NwQbfQ7BRp/zFx4ermbNmikvL09OpzPUzakRl8ul4uJi78BBbZObmxuU13E6nSosLNSqVatUXFzss68m1+aq98Fp+vTpmjp1qnc7JydHqampGjRokGJjY0PYMunbXUc1cdHX+mO3ZP2pR3O1bxYT0vbUJS6XSxkZGRo4cKAsFkuom4N6jv6GYKPPIdjoc5UrKirSzp07FR0drYiICEmekZJCV0nQ22K3mGu0QpzFYlF4eHiFv/OuXLlSd999t7799lvFx8fr+uuv18MPP6zwcE88eOONN/Twww/r559/VmRkpLp3766lS5cqKipKn376qaZNm6Yff/xRFotFnTp10ksvvaRWrVpVq12GYSg3N1cxMTFBuSZWUVGR7Ha7zj//fO93WKYmobLeByebzSabzeZXbrFYQv4Pw/sb9+twgUv/+WKH/vPFDnVrEaeRvVI1vFuKYiP4R6s6asP3iIaD/oZgo88h2Ohz/kpKSmQymRQWFuZdkrzAWazODwZ/dG7jQ5co0lr96xCZTCZv28vbvXu3hg0bprFjx+rFF1/U5s2bNXHiRNntdj344IPKysrStddeq1mzZumyyy5Tbm6uPvvsM5lMJrndbl1++eWaOHGiXnnlFTmdTq1du1Zms7naS7aXTc+rqG2nQlhYmEwmU4X9uyb9vd4Hp9ps2pAO6tsuUUvW7dSHm/bp211H9e2uo3r4nY0a2iVZV6Wl6uw28VydGgAAACfN3LlzlZqaqqefflomk0lnnnmm9uzZo7vvvlv333+/srKyVFxcrMsvv9w7itSlSxdJ0qFDh3T06FENGzZM7dq1kyR16NAhZO8lmEIanPLy8vTzzz97t7dt26bMzEzFx8erZcuWmj59unbv3q0XX3zRWyczM9N77IEDB5SZmSmr1aqOHTsGu/knzBxmUv8zm6r/mU2VnefQ0q93a8n6nfp5f57e+nq33vp6t9okRulPaS10ZY8WahobEfhJAQAAcErZLWZtfOiSkLzuybBp0yb16dPH54/z/fr1U15ennbt2qVu3brp4osvVpcuXXTJJZdo0KBBuvLKK9W4cWPFx8dr7NixuuSSSzRw4EANGDBAI0eOVHJy8klpW20W0mUJ1q9fr+7du6t79+6SpKlTp6p79+66//77JXkueLtjxw6fY8rqb9iwQYsXL1b37t01dOjQoLf9ZEuMtmni+W2Vccf5emtyX13dK1VRVrO2Zedr1ntb1Of/PtaE/6zTBz/ulaukbq3oAgAAUJ+YTCZFWsODfjtZs5AMw/B7rrKV7kwmk8xmszIyMrRixQp17NhRTz31lNq3b69t27ZJkhYuXKgvvvhCffv21ZIlS3TGGWfoyy+/PCltq81COuJ04YUXer+kiqSnp/uVVVW/PjCZTOrRsrF6tGys+4Z11LvfZ+m1dTu1/rfD+nDTfn24ab8So226okdzjeyVqnZNokPdZAAAANQhHTt21JtvvukToNasWaOYmBg1b95ckud30n79+qlfv366//771apVKy1dutS76FrZYMb06dPVp08fLV68WL179w7ZewoGznGqxaJs4RqZlqqRaan6eX+eXl+/U29+vUvZeQ49t+pXPbfqV6W1aqyRvVI1rGuyIq18nQAAADjm6NGj3lNdytx4442aM2eOpkyZoltuuUVbtmzRAw88oKlTpyosLExfffWVPvroIw0aNEhNmzbVV199pQMHDqhDhw7atm2bnn/+ef3xj39USkqKtmzZoq1bt+r6668PzRsMIn7TriNOaxqt6UM76M5L2uvjzfv12rqd+mTLfq3/7bDW/3ZYM5b9qOHdUjSyV6q6pzZiQQkAAADo008/9Z4WU2bMmDFavny5/vrXv6pbt26Kj4/X+PHj9be//U2SFBsbq1WrVmnOnDnKyclRq1at9MQTT2jIkCHat2+fNm/erP/85z86ePCgkpOTdcstt+imm24KxdsLKoJTHWMxh+mSTs10Sadm2pdTpDc27NLr63dq+8ECvbpup15dt1NnJEVrZFqqLuveXAnR/kuxAwAAoP5LT0+v8NSXMmvXrq2wvEOHDnrvvfcq3JeUlKSlS5eejObVOQSnOiwpNkI39z9Nky9sp6+2HdJr63Zq+Q9Z2rovT39/d5Mee2+zBnRI0sheqTr/9CYyhzEKBQAAAPweBKd6wGQyqXfbBPVum6AHL+2kZZl79Nr6nfpu11Gt+GGvVvywV8lxEbqyZwuNTEtVanxkqJsMAAAA1CkEp3omNsKi0b1baXTvVtqUlaMl63bq7czdyjpapKc+/llPffyz+rZL0FW9UnVJp2aKOEnXAwAAAADqM4JTPdYhOVYP/rGTpg89Ux/8uE+vrd+p1T9na80vB7Xml4OKjQjXiO7NNTItVZ2bx4W6uQAAAECtRXBqAGzhZg3vlqLh3VK063CBXl+/S29s2KXdRwr14he/6cUvflOnlFhd1StVl3ZrrrhIS6ibDAAAANQqYaFuAIKrReNI3THwDK26q78WjT9bw7omy2oO0497cnT/f39Ur0c/1G2vfqM1P2fL7a7fFxsGAAAAqosRpwbKHGbSeac30XmnN9HhfKfeztytJet2avPeXP03c4/+m7lHqfF2jeyZqivTWig5zh7qJgMAAAAhQ3CCGkdZdUO/Nhrbt7W+331US9bt1LLMPdp5qFBPZGzVkx9u1flnNNHItFQN6JAkazgDlQAAAGhYCE7wMplM6tqikbq2aKS//aGjVvyQpSXrduqrbYf06ZYD+nTLAcVHWXVZ9+a6qleqzkiKCXWTAQAAgKAgOKFCdqtZl/dooct7tND27Hy9tn6n3tiwS/tzHZq/epvmr96ms1Ib6apeqRreLUXRNroSAAAA6i/mXCGg1olRumvwmVoz7SLNH5OmQR2TFB5mUubOI5r+1vfq9fcPdefr32rd9kMyDBaUAAAAqE3WrFkjs9mswYMHh7opdRrDBKi2cHOYLu6QpIs7JOlArkNvfb1LS9bv1K8H8vXGBs8S522bRGlkWqou79FcTWMiQt1kAACABm/BggWaMmWKXnjhBe3YsUMtW7YMSTtcLpcslrp72RtGnPC7NImx6aYL2umjqRfojUl9NDKthSKtZv16IF//t2Kz+sz8WBNfXK8PN+5TcYk71M0FAAA4eQxDcuYH//Y7Zvbk5+frtdde05///GcNGzZM6enpPvuXLVumtLQ0RUREKDExUZdffrl3n8Ph0F133aXU1FTZbDadfvrpmj9/viQpPT1djRo18nmut99+WyaTybv94IMP6qyzztKCBQvUtm1b2Ww2GYah9957T4MHD1Z8fLwSEhI0bNgw/fLLLz7PtWvXLl199dWKj49XVFSU0tLS9NVXX2n79u0KCwvT+vXrfeo/9dRTatWq1Smd/cSIE06IyWRSWut4pbWO1/3DO+nd7/Zoybqd+nrHEWVs3KeMjfvUNMamK3q20Mi0VLVJjAp1kwEAAE6Mq0B6NCX4r3vPHslas9+llixZovbt26t9+/YaPXq0pkyZovvuu08mk0nvvvuuLr/8ct17771atGiRnE6n3n33Xe+x119/vb744gv961//Urdu3bRt2zZlZ2fX6PV//vlnvfbaa3rzzTdlNpslecLczTffrLPPPluFhYW6//77ddlllykzM1NhYWHKy8vTBRdcoObNm2vZsmVq1qyZvv76a7ndbrVu3VoDBgzQwoULlZaW5n2dhQsXauzYsT7B7WQjOOGkibaF66peLXVVr5b6aV+uXlu/U299vVv7cx2a9+kvmvfpLzq7TbyuSkvV0C7JslvNoW4yAABAvTZ//nyNHj1akjR48GDl5eXpo48+0oABA/TII4/o6quv1owZM7z1u3XrJknaunWrXnvtNWVkZGjAgAGSpLZt29b49Z1OpxYtWqQmTZp4y6644grl5OQoNjZWYWFhmj9/vpo2baqNGzeqc+fOWrx4sQ4cOKB169YpPj5eknTaaad5j58wYYImTZqk2bNny2az6dtvv1VmZqbeeuutmn9ANUBwwilxelKM7v1DR/31kjP18eZ9WrJup1ZuPaC12w5p7bZDenDZjxp+VoquSktV1xZxp/SvAwAAACeVJdIz+hOK162BLVu2aO3atd5AER4erquuukoLFizQgAEDlJmZqYkTJ1Z4bGZmpsxmsy644IITanKrVq18QpMk/fLLL5o+fbq+/vprZWdny+32nNaxY8cOde7cWZmZmerevbs3NB1vxIgRuuWWW7R06VJdffXVWrBggfr376/WrVufUFsDITjhlLKGh2lw52QN7pysrKOFenPDLr22fpd2HCrQ4q92aPFXO3Rmsxj9KS1Vl3Vvrvgoa6ibDAAAUDWTqcZT5kJh/vz5Ki4uVvPmzb1lhmHIYrHo8OHDstvtlR5b1T5JCgsL8zufyOVy+dWLivL/nC699FIlJyfrueeeU4sWLeR2u9W5c2c5nc5qvbbVatV1112nhQsX6vLLL9fixYs1Z86cKo85GVgcAkGTHGfXLRedrk/vvFCLJ56jEWelyBYeps17c/XwOxvV+9GPdPPLX2vl1gMqcbOsOQAAwO9VXFysF198UU888YQyMzO9t2+//VatWrXSyy+/rK5du+qjjz6q8PguXbrI7XZr5cqVFe5v0qSJcnNzlZ+f7y3LzMwM2K6DBw9q06ZN+stf/qKLL75YHTp00OHDh33qdO3aVZmZmTp06FClzzNhwgR9+OGHmjt3rlwul8+iFqcKI04IurAwk/q2S1TfdomaUejSsszdWrJ+p37YnaN3v8/Su99nqXkju67o2UJ/6tlCqfE1G5YGAABo6N555x0dPnxY48ePV1xcnM++K6+8UvPnz9eTTz6piy++WO3atdPVV1+t4uJirVixQnfddZdat26tMWPGaNy4cd7FIX777Tft379fI0eO1DnnnKPIyEjdc889mjJlitauXeu3Yl9FGjdurISEBP3nP//Raaedpl27dmnatGk+dUaNGqVHH31UI0aM0MyZM5WcnKxvvvlGKSkp6tOnjySpQ4cO6t27t+6++26NGzcu4CjVycCIE0Iqzm7RdX1a650p5+ndW8/VmD6tFGe3aPeRQv3ro590/uOfaPQLX2nZt3tU5CoJdXMBAADqhPnz52vAgAF+oUnyLM6QmZmp2NhYvf7661q2bJnOOussXXTRRfrqq6+89ebNm6crr7xSkydP1plnnqmJEyd6R5ji4+P10ksvafny5erSpYteeeUVPfjggwHbFRYWpsWLF+vbb79V165ddccdd+jxxx/3qWO1WvXBBx+oadOmGjp0qLp06aL/+7//867KV2b8+PFyOp0aN27c7/iEas5knMrFzmuhnJwcxcXF6ejRo4qNjQ11c1CBIleJ3v9xr15bv1Of/3zQWx5nt+iy7s01Mi1Vpzexa/ny5Ro6dGidvpAa6gaXy0V/Q1DR5xBs9LnKFRUVadu2bWrTpo0iIiJC3Zx6we12+6yq93s98sgjevXVV/X9999XWa+q77Am2YCpeqh1IixmXXpWc116VnPtPFSg19fv1OsbdinraJHS12xX+prt6pwSq2RTmPZ/8ZuaxtoVH2VVQpRNCdFWNY60yhrOYCoAAEB9lJeXp02bNumpp57Sww8/HLTXJTihVkuNj9TUQe1124Az9NlPB/Ta+p3K2LhPP+zJ0Q8KU8buLRUeFxsRroRom+KjrIqPsiox2lr62KaEKKsSSrcTojx1CFoAAAB1wy233KJXXnlFI0aMCNo0PYnghDrCHGbShe2b6sL2TXUo36m3v96pTzZsVGxiig4VuHQo36mD+U4dynfIbUg5RcXKKSrWtuz8wE8uKSYiXAmlISsh2uZ97AldNr/HBC0AAIDQSE9Pr9ZCFCcbwQl1TnyUVdf1bqmEQz9o6NCuPnOx3W5DRwtdpSHKqYN5jgofH8p3KjvPqcMFTpW4DeUWFSu3qFjbDxZUqw0xtnDFR1tLA1Zp0Crd9oxm+Y5s2cLNgZ8UAAAAtRbBCfVKWJhJjaOsalzNC+m63YZyilzKzisLVJ5wdbB0u2wU62Ce5/HhfKeK3YZyHcXKdRTrt2oGrWhbeLnpgf4jW8ePckVYCFoAANQmDWw9tXrlZH13BCc0aGFhJjWKtKpRZM2C1rFRLKcO5jt0qDRYlQ9aZSNbxW5DeY5i5dUwaJWFqMpGsRKibN5RLoIWAACnRtnMloKCgqBcKwgnn9PplCS/5cxriuAE1ED5oNWuSeD6hmEop7BYB48byTqU7yg3ylUauvIcfkFrx6HqBa0oq1nxpeEqsWzkKtqqxNLFL45NI7QpPtIqu5WgBQBAdZjNZjVq1Ej79++XJEVGRspkMoW4VXWb2+2W0+lUUVHRCS1HXt3XOnDggCIjIxUefmLRh+AEnEImk0lxkRbFRVrUtrpBq6jYG6IqPlfr2MjWoXynXCWG8p0lyj9UqJ2HCqvVLlt4mBpFWtTIblVcpEWN7BY1jrSqUWlbG9k9jxsd99huMfOfBQCgwWnWrJkkecMTToxhGCosLJTdbg/K7xVhYWFq2bLlCb8WwQmoRUwmk+LsFsXZaxa0KhzFKptGeNxjV4khR7Fb+3Ic2pfjqFH7rOYwxUVa1Pi40OUJVlafoBVnt6hxlFWN7BZFWglcAIC6y2QyKTk5WU2bNpXL5Qp1c+o8l8ulVatW6fzzzw/KBZetVutJGdkiOAF1WPmg1SYxKmB9w/BMAzxS4NLRQpeOFLh0pNCpwwUuHS1wlm6Xlhc4vY+PFnoCl7PErQO5Dh3IrVngsphNiisNVI0jLd7HZaErLtLqDWNloatRpEXRtnACFwCg1jCbzSd8ngw8n2NxcbEiIiKCEpxOFoIT0ICYTCbFRFgUE2FRag2OMwxDBc4SHS4NV+VDlzdklYauoz5hzCVniVuuEkPZeQ5l59UscIWHmcoFKWtp0PIPXcdPNYwhcAEAgJOM4AQgIJPJpChbuKJs4WrRuPrHGYahQldJabjyHcU6UujU0QKXN4wdH7qcxW4Vuw1l53muuSVV72LGkueCyWWjVo3KhS7PNEOrXxhrHGn1Bq6wMAIXAADwR3ACcMqYTCZFWsMVaQ1XSqOaLeFa6CwpN6LlmS54uMA3dB0pDV7lR8CKXG6VuA3vuV41EWaSN1DF2UvP5Yq0KsZm1oFdJh1dt1PJjaLUNMamJqU3i/nUrgYEAABqB4ITgFrJbjXLbrUrOa5mgauobISrktB1tFy5Z/TLs13oKpHbkA4XuHS4oKITf81asWuTX2l8lNUnSDWNifBuN42xqWmsZzvKxj+3qFhxiVuHCkoXdslzKjvfqQM5hdq816RGvxzUac3ilBwbwWgoAIQY/5MDqFciLGY1izOrWVxEjY4rcpUop9ATpg7nO32mDh7Kc+jbzb/I3jhJ2flO7c/xnK9VXG5ka/Pe3CqfP9Jq9gSpmIhjISv22HbT0lvjSCu/INdxxSVuHS5w+VxKoPwlBsqu51Z2fbcjFQZ1STLr9W0bJHkuIdAmMUqtE6LUpkmU2iQeuyVEWTmnDwCCgOAEAPIErgiLWU1j/QOXy+XSctdPGjq0u3f1H7fb0OECp/bnOjy3nCIdyHNof47Du/Lg/twi7c91qMBZogJnibYfLND2g1Vf1Dg8zKTE6LJQZVOT44JVk9JRrCbRNlnDmSYYDD5BKN9xLPj4XV/NE46OFLpkGDV7DZNJahzpuVB1fJRnlcmde7JUaI7WzsOFchS7tXlvboUBPSYiXG0To9Q60TdQtU6MUmxE3VmtCgBqO4ITAPwOYWEmJUTblBBtU4fkquvmOYo9QSqnyBu0yoKVp9yhA6UjEsVuQ3tzirQ3pyhgGxpHWnynB8ba1CT62PTAssDFsu6+SkpDr/+1zjzXQyt7XDZKdCJBKL40CCVGe+4TomxKqOBx40irzOVGGl0ul5Yv362hQ8+VKcys3UcK9Wt2vrYdyNf2g/nalp2vXw/ka8/RQuUWFevbXUf17a6jfu1IjLapTWJkaZiKLn0crVYJkYqwsKQyANQEwQkATrFoW7iibeEBr7XlLHYrO68sVJWOWJWGKs9IVpE3dBW7De/5WFv35VX5vHaLWU29oeq46YLlpg8mRNXNaYJlQehQvlPZpWHH89gThI499twOFzh/VxBqZLd4Ak+057PyhJ7yj61KjLZVGIRORLg5TK0SotQqIUr92/vuK3KVaMehAv1aFqgOlIaq7HzvJQCy8xxat/2w3/tJibP7jFCV3Vo0tiucRU8AwA/BCQBqCWt4mFIa2QOuQOh2GzpS6DoWrMoHrdxyUwVzipTvLFGhq0S/HSzQbwGmCZrDTEqMtvqdd9WkdGrgsemDNtnCT91oRYnb0JGCCs4HqnCE6PcFIckzYuc/CuQJRvGlYSghyuadOlcbw0SExawzkmJ0RlKM377cIpe2Zxfo1+w8bc8u0LbsPG+oyi0q1u4jhdp9pFCrf872OS48zKSW8ZE+U/7aJnrOrUqKYZEKAA0XwQkA6piwMJN3CtiZzaqum182TbD81MDS6YFl2wdyPefqlLgN7ctxaF9O4AsVx9ktpasG+k8P9E4fjLUpxhYutyEdKXAeN/Lj8BkFyi63eMLvDUKNSoNQYlT54GP1GSWKLw1DtTUInUwxERZ1aRGnLi3ifMoNw7OoybbsfL/b9oP5KnK59WtpwDqe3WJWq4RItS1doKJ1QlTp42g1jrQwJRRAvUZwAoB6rOzCxa0DTBN0lZSbJpjjex5W2XlZ2aXbrhJDRwtdOlro0k/7q54maAsPk6vELffvCEJxdos3/CRE2UpDT2kYivadItc40so1tarJZDp2fl5a63iffe7Sc+y2lwYnb6DKzteOQwUqdJVUukhFbES42jSJ9oxOlRupap0YpWiW4wdQD/AvGQBAFnOYkuMCXzfLMAwdKXD5ByvvuVjHRrFyHcVyFLu9x8bZLT5hJz7KdmzRhLIRodL9BKHQCAszeaeL9j0t0Wefq8StXYcLy4WqsimA+dp9pFA5RcX6ducRfbvziN/zNomxqU25IFX2uGVC5Cmd9gkPwzDkKHaXrvBZ7F3ps8BZrAJHiQpcJcovcmpTtkkRWw4oLtKzqIznDy9mRdvCZbeYGVFEg0dwAgBUm8lkUuMoqxpHWdW+mf95NeUVOIuVnetUhCVMjaMIQnWdxRzmPe+p/3H7ilwl2n4w/1ioKrf6X3ae0xum12475HOcySQ1b2SvIFRFq3lj+0lbYKOucJW4S4NMabhxlIYbV4kKnSXKdxSr0FUaehyldSrYV/5xYWlAqt6or1kv/vRNhXvCTFKUNVzREeHekexom9lTZjuuzPv4uLJydbmcAuqikAanVatW6fHHH9eGDRuUlZWlpUuXasSIEVUes3LlSk2dOlU//vijUlJSdNddd2nSpEnBaTAAoNoireFqmcDf5xqCCItZZzaL1ZnNYv325RS5tD372BLqZYFq24F85TqKtetwoXYdLtRnP/kuUmExly1ScWwZ9bLglhRrC9noR4nb8IQSx7GRm0JXsfIdvo8Ly0Z1XKWjOqX7vIHouHBU6CqRq+R3zGmtIWt4mKKsZkVaw2W3mhVZerOZw7R7335FRDdSgbNEeY5i5TuKle8skSS5DSnXUaxcR/HJaYc5rDSE+Yav6NJRrvLBq/KQ5glykRYzi5YgKEL6P1p+fr66deumG264QVdccUXA+tu2bdPQoUM1ceJEvfTSS/r88881efJkNWnSpFrHAwCA4IqNsKhri0bq2qKRT7lhGDpYtkjFAc9IVVnA2nYwX85it345kK9fDvgvUhFpNat1wnFLqTeJUpuEKDWOssowDBW53H7T0srCTH65x+XrFFa1z+UZySk//fRUCQ8zyW71BIVIq7lcwPHdjvIJP+HeEGS3hivKW+/YY7vFXOmiKJ5rhy3X0KG9vRf6ljznvRWUvveyMOW59y3zPD5W5lPX6amf5yiWs/Tzc5a4SxeHOTmfWZT1+LBl9gtZUVbf8vL35QObLTyMaYmoUEiD05AhQzRkyJBq13/22WfVsmVLzZkzR5LUoUMHrV+/Xv/4xz8ITgAA1CEmk0mJ0TYlRtvUq4JFKrJyikqvS5WnbeWWU995uFAFzhJtzMrRxqwcv+e1hYfJWeL+XSsz1qz9UqSlNKTYPKGkogDjCTjHHh8fgKKOG/mJtNauaWxhYSZvsEg6Cc/nKnH7hC/f4HVslKt88Mor8oSvsmBWvm7ZFMR8Z4nynSXanxt4VdBAwsNMFY9+WSuejmi3mGUND5PFHCZreOnNfNx96c1iNslmNnu3G9p01LquTs2h+OKLLzRo0CCfsksuuUTz58+Xy+Xy+QtJGYfDIYfj2A9RTo7nH1mXyyWXy3VqG4xTpuy74ztEMNDfEGz0OalpVLiaRsXpnNa+y6mXLVKxrfTaZJ5l1D33e3McfiNCEZawcqGmdBTGcmw0JtJqrnB/+ZEdu+VYwCnbH2E5RaMSRolcrpKT/7wBBLPPRVlMirJYpGj/39tqomxksfyIVtnjsgCWXzY6Vj54+YSwktJjilXo8vSdYvexlUNPtTCTfAKWxVz22HTctufeYjb5hDPLcQHNu7+KY44PdccfYzGf+kBXm/6Nq0kb6lRw2rt3r5KSfP/ekZSUpOLiYmVnZys5OdnvmJkzZ2rGjBl+5R988IEiIyNPWVsRHBkZGaFuAhoQ+huCjT5XtSRJSeFS7yTPhrNEynFJ1jDJavbcV/v3P1fprdzUMUfp7fBJbndtVl/6XJikmNKbl6X0Vgm3ITlKPLeisnu3ya/MUWIq91hyuqViQypxm1RsSMWl28Xe8vLbJr/XLHK5VeQ69VNAayJMhsLDpHCTZC699982Kik//t6QuWy7rK7JM7KXvzxDUSeWn09YQUHVF4cvr04FJ0l+f90xSsfiK/urz/Tp0zV16lTvdk5OjlJTUzVo0CDFxvqfxIq6weVyKSMjQwMHDqxwpBE4mehvCDb6HIKNPhcchmGo2G3IWeyWs8QtZ7FbrpLjt489dhYbvtsl5ep7t90+xzvLPZ+rrLzE81yVHXP8wiRumeR0S05JqnQA9MRHpRbf0EO92iYGrngKlc1Gq446FZyaNWumvXv3+pTt379f4eHhSkhIqPAYm80mm83mV26xWPiHoR7ge0Qw0d8QbPQ5BBt97tSzSqptc54Mw/AEsvLhrdgtR3FFYc7/cYX1i30Dn8+xrhLtPXBQ8TH2kPe3mrx+nQpOffr00f/+9z+fsg8++EBpaWkh/9ABAACAushkMnnPq5L/eMNJV7aKY7smUaf+xU6ikC7bkpeXp8zMTGVmZkryLDeemZmpHTt2SPJMs7v++uu99SdNmqTffvtNU6dO1aZNm7RgwQLNnz9fd955ZyiaDwAAAKCBCOmI0/r169W//7Hrj5edizRmzBilp6crKyvLG6IkqU2bNlq+fLnuuOMOPfPMM0pJSdG//vUvliIHAAAAcEqFNDhdeOGF3sUdKpKenu5XdsEFF+jrr78+ha0CAAAAAF+15wprAAAAAFBLEZwAAAAAIACCEwAAAAAEQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AQAAAEAABCcAAAAACIDgBAAAAAABEJwAAAAAIACCEwAAAAAEQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAgh5cJo7d67atGmjiIgI9ezZU5999lmV9Z955hl16NBBdrtd7du314svvhiklgIAAABoqMJD+eJLlizR7bffrrlz56pfv3567rnnNGTIEG3cuFEtW7b0qz9v3jxNnz5d//73v9WrVy+tXbtWEydOVOPGjTV8+PAQvAMAAAAADUFIR5xmz56t8ePHa8KECerQoYPmzJmj1NRUzZs3r8L6ixYt0k033aSrrrpKbdu21dVXX63x48frscceC3LLAQAAADQkIRtxcjqd2rBhg6ZNm+ZTPmjQIK1Zs6bCYxwOhyIiInzK7Ha71q5dK5fLJYvFUuExDofDu52TkyNJcrlccrlcJ/o2ECJl3x3fIYKB/oZgo88h2OhzCKba1N9q0oaQBafs7GyVlJQoKSnJpzwpKUl79+6t8JhLLrlEL7zwgkaMGKEePXpow4YNWrBggVwul7Kzs5WcnOx3zMyZMzVjxgy/8g8++ECRkZEn580gZDIyMkLdBDQg9DcEG30OwUafQzDVhv5WUFBQ7bohPcdJkkwmk8+2YRh+ZWXuu+8+7d27V71795ZhGEpKStLYsWM1a9Ysmc3mCo+ZPn26pk6d6t3OyclRamqqBg0apNjY2JP3RhBULpdLGRkZGjhwYIUjjcDJRH9DsNHnEGz0OQRTbepvZbPRqiNkwSkxMVFms9lvdGn//v1+o1Bl7Ha7FixYoOeee0779u1TcnKynn/+ecXExCgxMbHCY2w2m2w2m1+5xWIJ+ReFE8f3iGCivyHY6HMINvocgqk29LeavH7IFoewWq3q2bOn3xBdRkaG+vbtW+WxFotFLVq0kNls1quvvqphw4YpLCzkK6sDAAAAqKdCOlVv6tSpuu6665SWlqY+ffro+eef144dOzRp0iRJnml2u3fv9l6raevWrVq7dq3OOeccHT58WLNnz9YPP/yg//znP6F8GwAAAADquZAGp6uuukoHDx7UQw89pKysLHXu3FnLly9Xq1atJElZWVnasWOHt35JSYmeeOIJbdmyRRaLRf3799eaNWvUunXrEL0DAAAAAA1ByBeHmDx5siZPnlzhvvT0dJ/tDh066JtvvglCqwAAAADgGE4MAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AQAAAEAABCcAAAAACIDgBAAAAAABEJwAAAAAIACCEwAAAAAEQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AQAAAEAABCcAAAAACIDgBAAAAAABEJwAAAAAIIDfFZyKi4v14Ycf6rnnnlNubq4kac+ePcrLyzupjQMAAACA2iC8pgf89ttvGjx4sHbs2CGHw6GBAwcqJiZGs2bNUlFRkZ599tlT0U4AAAAACJkajzjddtttSktL0+HDh2W3273ll112mT766KOT2jgAAAAAqA1qPOK0evVqff7557JarT7lrVq10u7du09awwAAAACgtqjxiJPb7VZJSYlf+a5duxQTE3NSGgUAAAAAtUmNg9PAgQM1Z84c77bJZFJeXp4eeOABDR069GS2DQAAAABqhRpP1XvyySfVv39/dezYUUVFRbrmmmv0008/KTExUa+88sqpaCMAAAAAhFSNg1NKSooyMzP1yiuv6Ouvv5bb7db48eN17bXX+iwWAQAAAAD1xe+6jpPdbte4ceP09NNPa+7cuZowYcLvDk1z585VmzZtFBERoZ49e+qzzz6rsv7LL7+sbt26KTIyUsnJybrhhht08ODB3/XaAAAAAFAdNR5xevHFF6vcf/3111f7uZYsWaLbb79dc+fOVb9+/fTcc89pyJAh2rhxo1q2bOlXf/Xq1br++uv15JNPavjw4dq9e7cmTZqkCRMmaOnSpTV9KwAAAABQLTUOTrfddpvPtsvlUkFBgaxWqyIjI2sUnGbPnq3x48drwoQJkqQ5c+bo/fff17x58zRz5ky/+l9++aVat26tW2+9VZLUpk0b3XTTTZo1a1ZN3wYAAAAAVFuNg9Phw4f9yn766Sf9+c9/1l//+tdqP4/T6dSGDRs0bdo0n/JBgwZpzZo1FR7Tt29f3XvvvVq+fLmGDBmi/fv364033tAf/vCHSl/H4XDI4XB4t3NyciR5Ap/L5ap2e1G7lH13fIcIBvobgo0+h2CjzyGYalN/q0kbTIZhGCfjRdevX6/Ro0dr8+bN1aq/Z88eNW/eXJ9//rn69u3rLX/00Uf1n//8R1u2bKnwuDfeeEM33HCDioqKVFxcrD/+8Y964403ZLFYKqz/4IMPasaMGX7lixcvVmRkZLXaCgAAAKD+KSgo0DXXXKOjR48qNja2yro1HnGqjNls1p49e2p8nMlk8tk2DMOvrMzGjRt166236v7779cll1yirKws/fWvf9WkSZM0f/78Co+ZPn26pk6d6t3OyclRamqqBg0aFPDDQe3lcrmUkZGhgQMHVhqagZOF/oZgo88h2OhzCKba1N/KZqNVR42D07Jly3y2DcNQVlaWnn76afXr16/az5OYmCiz2ay9e/f6lO/fv19JSUkVHjNz5kz169fPOyWwa9euioqK0nnnnae///3vSk5O9jvGZrPJZrP5lVsslpB/UThxfI8IJvobgo0+h2CjzyGYakN/q8nr1zg4jRgxwmfbZDKpSZMmuuiii/TEE09U+3msVqt69uypjIwMXXbZZd7yjIwMXXrppRUeU1BQoPBw3yabzWZJngAHAAAAAKdCjYOT2+0+aS8+depUXXfddUpLS1OfPn30/PPPa8eOHZo0aZIkzzS73bt3e5dAHz58uCZOnKh58+Z5p+rdfvvtOvvss5WSknLS2gUAAAAA5Z20c5x+j6uuukoHDx7UQw89pKysLHXu3FnLly9Xq1atJElZWVnasWOHt/7YsWOVm5urp59+Wn/5y1/UqFEjXXTRRXrsscdC9RYAAAAANADVCk7lF1cIZPbs2TVqwOTJkzV58uQK96Wnp/uVTZkyRVOmTKnRawAAAADAiahWcPrmm2+q9WSVrYYHAAAAAHVZtYLTJ598cqrbAQAAAAC1VlioGwAAAAAAtd3vWhxi3bp1ev3117Vjxw45nU6ffW+99dZJaRgAAAAA1BY1HnF69dVX1a9fP23cuFFLly6Vy+XSxo0b9fHHHysuLu5UtBEAAAAAQqrGwenRRx/Vk08+qXfeeUdWq1X//Oc/tWnTJo0cOVItW7Y8FW0EAAAAgJCqcXD65Zdf9Ic//EGSZLPZlJ+fL5PJpDvuuEPPP//8SW8gAAAAAIRajYNTfHy8cnNzJUnNmzfXDz/8IEk6cuSICgoKTm7rAAAAAKAWqHZwyszMlCSdd955ysjIkCSNHDlSt912myZOnKhRo0bp4osvPiWNBAAAAIBQqvaqej169FD37t01YsQIjRo1SpI0ffp0WSwWrV69Wpdffrnuu+++U9ZQAAAAAAiVao84ff755+rRo4f+8Y9/qF27dho9erRWrlypu+66S8uWLdPs2bPVuHHjU9lWAAAAAAiJagenPn366N///rf27t2refPmadeuXRowYIDatWunRx55RLt27TqV7QQAAACAkKnx4hB2u11jxozRp59+qq1bt2rUqFF67rnn1KZNGw0dOvRUtBEAAAAAQqrGwam8du3aadq0abr33nsVGxur999//2S1CwAAAABqjWovDnG8lStXasGCBXrzzTdlNps1cuRIjR8//mS2DQAAAABqhRoFp507dyo9PV3p6enatm2b+vbtq6eeekojR45UVFTUqWojAAAAAIRUtYPTwIED9cknn6hJkya6/vrrNW7cOLVv3/5Utg0AAAAAaoVqBye73a4333xTw4YNk9lsPpVtAgAAAIBapdrBadmyZaeyHQAAAABQa53QqnoAAAAA0BAQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AQAAAEAABCcAAAAACIDgBAAAAAABEJwAAAAAIACCEwAAAAAEQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAAQQ8uA0d+5ctWnTRhEREerZs6c+++yzSuuOHTtWJpPJ79apU6cgthgAAABAQxPS4LRkyRLdfvvtuvfee/XNN9/ovPPO05AhQ7Rjx44K6//zn/9UVlaW97Zz507Fx8frT3/6U5BbDgAAAKAhCWlwmj17tsaPH68JEyaoQ4cOmjNnjlJTUzVv3rwK68fFxalZs2be2/r163X48GHdcMMNQW45AAAAgIYkPFQv7HQ6tWHDBk2bNs2nfNCgQVqzZk21nmP+/PkaMGCAWrVqVWkdh8Mhh8Ph3c7JyZEkuVwuuVyu39Fy1AZl3x3fIYKB/oZgo88h2OhzCKba1N9q0oaQBafs7GyVlJQoKSnJpzwpKUl79+4NeHxWVpZWrFihxYsXV1lv5syZmjFjhl/5Bx98oMjIyJo1GrVORkZGqJuABoT+hmCjzyHY6HMIptrQ3woKCqpdN2TBqYzJZPLZNgzDr6wi6enpatSokUaMGFFlvenTp2vq1Kne7ZycHKWmpmrQoEGKjY39XW1G6LlcLmVkZGjgwIGyWCyhbg7qOfobgo0+h2CjzyGYalN/K5uNVh0hC06JiYkym81+o0v79+/3G4U6nmEYWrBgga677jpZrdYq69psNtlsNr9yi8US8i8KJ47vEcFEf0Ow0ecQbPQ5BFNt6G81ef2QLQ5htVrVs2dPvyG6jIwM9e3bt8pjV65cqZ9//lnjx48/lU0EAAAAAEkhnqo3depUXXfddUpLS1OfPn30/PPPa8eOHZo0aZIkzzS73bt368UXX/Q5bv78+TrnnHPUuXPnUDQbAAAAQAMT0uB01VVX6eDBg3rooYeUlZWlzp07a/ny5d5V8rKysvyu6XT06FG9+eab+uc//xmKJgMAAABogEK+OMTkyZM1efLkCvelp6f7lcXFxdVo9QsAAAAAOFEhvQAuAAAAANQFBCcAAAAACIDgBAAAAAABEJwAAAAAIACCEwAAAAAEQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AQAAAEAABCcAAAAACIDgBAAAAAABEJwAAAAAIACCEwAAAAAEQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABBAyIPT3Llz1aZNG0VERKhnz5767LPPqqzvcDh07733qlWrVrLZbGrXrp0WLFgQpNYCAAAAaIjCQ/niS5Ys0e233665c+eqX79+eu655zRkyBBt3LhRLVu2rPCYkSNHat++fZo/f75OO+007d+/X8XFxUFuOQAAAICGJKTBafbs2Ro/frwmTJggSZozZ47ef/99zZs3TzNnzvSr/95772nlypX69ddfFR8fL0lq3bp1MJsMAAAAoAEKWXByOp3asGGDpk2b5lM+aNAgrVmzpsJjli1bprS0NM2aNUuLFi1SVFSU/vjHP+rhhx+W3W6v8BiHwyGHw+HdzsnJkSS5XC65XK6T9G4QbGXfHd8hgoH+hmCjzyHY6HMIptrU32rShpAFp+zsbJWUlCgpKcmnPCkpSXv37q3wmF9//VWrV69WRESEli5dquzsbE2ePFmHDh2q9DynmTNnasaMGX7lH3zwgSIjI0/8jSCkMjIyQt0ENCD0NwQbfQ7BRp9DMNWG/lZQUFDtuiGdqidJJpPJZ9swDL+yMm63WyaTSS+//LLi4uIkeab7XXnllXrmmWcqHHWaPn26pk6d6t3OyclRamqqBg0apNjY2JP4ThBMLpdLGRkZGjhwoCwWS6ibg3qO/oZgo88h2OhzCKba1N/KZqNVR8iCU2Jiosxms9/o0v79+/1GocokJyerefPm3tAkSR06dJBhGNq1a5dOP/10v2NsNptsNptfucViCfkXhRPH94hgor8h2OhzCDb6HIKpNvS3mrx+yJYjt1qt6tmzp98QXUZGhvr27VvhMf369dOePXuUl5fnLdu6davCwsLUokWLU9peAAAAAA1XSK/jNHXqVL3wwgtasGCBNm3apDvuuEM7duzQpEmTJHmm2V1//fXe+tdcc40SEhJ0ww03aOPGjVq1apX++te/aty4cZUuDgEAAAAAJyqk5zhdddVVOnjwoB566CFlZWWpc+fOWr58uVq1aiVJysrK0o4dO7z1o6OjlZGRoSlTpigtLU0JCQkaOXKk/v73v4fqLQAAAABoAEK+OMTkyZM1efLkCvelp6f7lZ155pm1YgUOAAAAAA1HSKfqAQAAAEBdQHACAAAAgAAITgAAAAAQAMEJAAAAAAIgOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAAhOAAAAABAAwQkAAAAAAiA4AQAAAEAA4aFuAAAAwAkrcUn5B6SiHMkaKVmjJVuMZLaEumUA6gmCEwAAqJ0MQyo8LOXtl/L2lbvf619WcLDi5zDbJGuUZIuWrDGl99GVbJeGrar2h5mD+xmgdnGXSK5Cz6249N5d4tlnMkky+d979x1fRwHqV2efqn6u3/M63mNwPIITAAAILmfBcUFoXwXhqPTe7ar+85rMUkSs5/lLHJ6yEodU6JAKD52ctlsiqwhaNdi2Rnlu/JJ64gzDM+LoKigNNQVScdGxx66iY/vKwo63vHz9gmOhyFVY8b4SZ6jfbZCdYAjz7vM9Ltxk0mCnU+q+VGrZK5hv6IQQnAAAwIkrKZYKsqsXiBw5NXtue2MpOkmKblp6X/5xuTJ7vBRWevp2iUty5ErOPMmRV3pf1Xa+5Mwtt++4Ou5iz/O6Cjy3/P0n4UMzHReqTjCMhdtqVxBzu0uDSlXBpVxYqWxfZaGmfH3DHfz3Fx7huYWFSzI8Aa78vcruKttnVLCvivohUa5dJ7EZJkk2ScVlo3V1BMEJAABUzDCkoqNVBKFyU+bys1Wj36zCIyoIQRU9buoJBDVltkiR8Z7biTIMqdhRjfBVne3Se5X+QuzM9dxOhrDwSoJV4GmKpjCbEnI3y/SzVTKclYSdKkZiKtpXXHRy3ldNmMI8o4IWuxRu99z73CI9fa/ssSWikvqV7SstD7cfC+nBZNQkhFU3oB1fRyfwXMc/Z8XP5Sou1merVum8ph1O4odz6hGcAABoaFxFnhGTvP1S7t6qp8qVTXmrDlOYFNWkiiBUrswWU7tGR6piMpX+Eh0hRSWe+PMZRukIV/7JCWOuAs/zuouloiOeWw2FSzpXkn4+8bdXIbP1uOASWUWoKdtXRXDxlh/3XGZr3elXv0d9OQfJ5VKu/VfPd1eHEJwAAKgP3CWeBRICnTOUt88zilQTtjgpprIpcuWCUWQCiydUh8nkGe2xRUtKOvHnc5dUMKqV6x+0nPkV7PPcG4485RU6FN0oUSZrlH+oqSy4VHcEh36BeoDgBKDhcpd4zrUoPOL5RbKo9P64bXPBIZ2z8xeZX3vZM/0nzOw5CT0s3PPYbzvc85d3n22zZ1qH93FNj62obg2PPf6168NfLes7w/Asr13lOUOlj/MPSEYNzhcw2wIHobKpchb7qXuPOHFhZikiznP7nYpdLn28fLmGDh0qi4Ul3IGKEJwA1G2uIk/AqTL8VLT/aOkJ6oHPyQiT1EyScr49RW8iVEzVCFkVha4KAqBfYCu3LZN858dLfnPjK90n/33e7QqOq9a+QK8f4LhT9vreF1e44daAIwcU/v1NnvNLqs3kmUpWaRAqF4gi4gjPAFADBCcAoeV2ewJMRYEnwEiQCo/U7PyLylgipYhGnl8k7aX3EY28j0usMfpuyzZ16dJF4SbDM1LlLvH8dd9dXPG2UXKs3F1cbp/7uO2KnqvYs0KUz3ZJBcdW47mqHIEwPEs912S5ZwSFSVJU+QJrzLEA5DdlrtzjyETJzH/tAHAq8K8rgBPnKqr+aM/x4aeoeqM+VTKFHZumUi7wVBiGvPsbHTsm3Frl07tdLu3IXq7OZw2V6toUFsOoJIRVI/xVGuACBcLjjvWq7GKN5atUtK+C47zbVe2rxvNU9frVeo0TfX1VuK+4xK0v1n2j3gNHyNIoxXO9HwBASBGcAHh+6XXmloaaI5WP7vhtlz4+GUvOhtsDBJ4438BTfp81OjTLwtYFJtOxKXeoMwyXS4c25UuNW9e9sA4A9RTBCaiPHHml11U5UHrS+H4p74CnrOCgfxhy5OjELx5oOjaCU2XgaVxxOPo912kBAAAIEoITUBcYhmfZ2LKVs8qvopW3v1w4Ki0ru6ZHTYVHVG+Ep6JzgawxjPoAAIB6i+AEhEr5MFQ++JQfIcovW274QA1X1pJnwYPyF6IsexyZeCwQHR+GLBEn/30CAADUAwQn4GQyDM+FBisaFaooGP2eMBTdVIoqvbZKVJPSFbWaHCsr22+LPjXvEQAAoAEiOAGBGIbnHCDvCFAFU+PKl9V0oQRLlCf4lB8VOj4ElQUjwhAAAEBIEJzQMJUPQ3n7Kp4aV76spmHIGl0uBDU5dp2ViqbOscwwAABArUdwQv1hGJ4V4rwjQJWsKldWVtMLp1qj/UeAjp8mRxgCAAColwhOqFvy9kt7MhW2+2udtWONzEtekgqyTyAMxVR8fpB36ly5kGSNPDXvCQAAALUewQm1V94BKStT2pNZev+NlLNbkmSW1EqSDlZwnC32uGlyTSs+fyiqCWEIAAAA1UJwQu2Qn10akL7x3O/JlHJ2VVDRJCWeLnezrtpy0K3Tz+qn8LgU35BksQe37QAAAKj3CE4IvoJDntGjPd8cG1E6urPiugmnSylnSSndpeSzpOSuki1GJS6Xti5frtN6DJUsluC1HQAAAA0SwQmnVsGhY9PsyqbcHdlRcd2E0zzhqCwoNesqRcQGrakAAABAZQhOOHkKD/uej7QnUzryW8V149seG0VK6e4ZSYqIC15bAQAAgBoIeXCaO3euHn/8cWVlZalTp06aM2eOzjvvvArrfvrpp+rfv79f+aZNm3TmmWee6qaivMLDUta3pecjlU65O7y94rqN23jCUfmRJHujoDUVAAAAOFEhDU5LlizR7bffrrlz56pfv3567rnnNGTIEG3cuFEtW7as9LgtW7YoNvbYFK4mTZoEo7kNV+ERT0gqOx9pzzfS4W0V123c+riRpG6EJAAAANR5IQ1Os2fP1vjx4zVhwgRJ0pw5c/T+++9r3rx5mjlzZqXHNW3aVI0aNQpSKxuYoqNS1nflFm74Rjr0a8V1G7U6buGGblJkfBAbCwAAAARHyIKT0+nUhg0bNG3aNJ/yQYMGac2aNVUe2717dxUVFaljx47629/+VuH0vTIOh0MOx7GLoubk5EiSXC6XXC7XCbyDesCRK9Pe72TKypRp77ee+0pCkhHXUkZyNxnJZ8lo1k1Gs64Vh6QgfaZl312D/w4RFPQ3BBt9DsFGn0Mw1ab+VpM2hCw4ZWdnq6SkRElJST7lSUlJ2rt3b4XHJCcn6/nnn1fPnj3lcDi0aNEiXXzxxfr00091/vnnV3jMzJkzNWPGDL/yDz74QJGRDefip+ElhYor/E2NCrYprmC7GhVsV4wjq8K6BdZEHbG31pHINjoS2VpHI1vLGR7j2XlE0pECafOXQWt7VTIyMkLdBDQg9DcEG30OwUafQzDVhv5WUFBQ7bomwzCMU9iWSu3Zs0fNmzfXmjVr1KdPH2/5I488okWLFmnz5s3Vep7hw4fLZDJp2bJlFe6vaMQpNTVV2dnZPudJ1SvOPJn2fn9sFCnrW+ngzzLJ/6s2Ylt4RpKalY4mJXeTIhNC0OiacblcysjI0MCBA2XhOk44xehvCDb6HIKNPodgqk39LScnR4mJiTp69GjAbBCyEafExESZzWa/0aX9+/f7jUJVpXfv3nrppZcq3W+z2WSz2fzKLRZLyL+ok8KZ7zknqfwS4NlbpQpCkmKb+y7ckHKWTFGJMgW3xSdVvfkeUSfQ3xBs9DkEG30OwVQb+ltNXj9kwclqtapnz57KyMjQZZdd5i3PyMjQpZdeWu3n+eabb5ScnHwqmlj7OPOlvd/7Xispe6tkuP3rxqQcWwK87KKy0U2D2lwAAACgvgjpqnpTp07Vddddp7S0NPXp00fPP/+8duzYoUmTJkmSpk+frt27d+vFF1+U5Fl1r3Xr1urUqZOcTqdeeuklvfnmm3rzzTdD+TZODWeBtO+HY6NIe76RsrdUEpKSfUaRlHyWFFP9UTsAAAAAVQtpcLrqqqt08OBBPfTQQ8rKylLnzp21fPlytWrVSpKUlZWlHTt2eOs7nU7deeed2r17t+x2uzp16qR3331XQ4cODdVbODlchdLeH3yXAD+wueKQFN3MdwnwlLOkmGbBbS8AAADQwIQ0OEnS5MmTNXny5Ar3paen+2zfdddduuuuu4LQqiD5dom05l/S/k2SUeK/P6pp6ShSuZGk2AYyLREAAACoRUIenBq0EqdnOp4kRTXxW7hBMcmSqS4v3QAAAADUDwSnUDrtYunqxaUjSSmEJAAAAKCWIjiFUmyK5wYAAACgVgsLdQMAAAAAoLYjOAEAAABAAAQnAAAAAAiA4AQAAAAAARCcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAAQQHuoGBJthGJKknJycELcEJ8LlcqmgoEA5OTmyWCyhbg7qOfobgo0+h2CjzyGYalN/K8sEZRmhKg0uOOXm5kqSUlNTQ9wSAAAAALVBbm6u4uLiqqxjMqoTr+oRt9utPXv2KCYmRiaTKdTNwe+Uk5Oj1NRU7dy5U7GxsaFuDuo5+huCjT6HYKPPIZhqU38zDEO5ublKSUlRWFjVZzE1uBGnsLAwtWjRItTNwEkSGxsb8h84NBz0NwQbfQ7BRp9DMNWW/hZopKkMi0MAAAAAQAAEJwAAAAAIgOCEOslms+mBBx6QzWYLdVPQANDfEGz0OQQbfQ7BVFf7W4NbHAIAAAAAaooRJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcEKdMXPmTPXq1UsxMTFq2rSpRowYoS1btoS6WWhAZs6cKZPJpNtvvz3UTUE9tnv3bo0ePVoJCQmKjIzUWWedpQ0bNoS6WaiHiouL9be//U1t2rSR3W5X27Zt9dBDD8ntdoe6aagnVq1apeHDhyslJUUmk0lvv/22z37DMPTggw8qJSVFdrtdF154oX788cfQNLYaCE6oM1auXKmbb75ZX375pTIyMlRcXKxBgwYpPz8/1E1DA7Bu3To9//zz6tq1a6ibgnrs8OHD6tevnywWi1asWKGNGzfqiSeeUKNGjULdNNRDjz32mJ599lk9/fTT2rRpk2bNmqXHH39cTz31VKibhnoiPz9f3bp109NPP13h/lmzZmn27Nl6+umntW7dOjVr1kwDBw5Ubm5ukFtaPSxHjjrrwIEDatq0qVauXKnzzz8/1M1BPZaXl6cePXpo7ty5+vvf/66zzjpLc+bMCXWzUA9NmzZNn3/+uT777LNQNwUNwLBhw5SUlKT58+d7y6644gpFRkZq0aJFIWwZ6iOTyaSlS5dqxIgRkjyjTSkpKbr99tt19913S5IcDoeSkpL02GOP6aabbgphayvGiBPqrKNHj0qS4uPjQ9wS1Hc333yz/vCHP2jAgAGhbgrquWXLliktLU1/+tOf1LRpU3Xv3l3//ve/Q90s1FPnnnuuPvroI23dulWS9O2332r16tUaOnRoiFuGhmDbtm3au3evBg0a5C2z2Wy64IILtGbNmhC2rHLhoW4A8HsYhqGpU6fq3HPPVefOnUPdHNRjr776qr7++mutW7cu1E1BA/Drr79q3rx5mjp1qu655x6tXbtWt956q2w2m66//vpQNw/1zN13362jR4/qzDPPlNlsVklJiR555BGNGjUq1E1DA7B3715JUlJSkk95UlKSfvvtt1A0KSCCE+qkW265Rd99951Wr14d6qagHtu5c6duu+02ffDBB4qIiAh1c9AAuN1upaWl6dFHH5Ukde/eXT/++KPmzZtHcMJJt2TJEr300ktavHixOnXqpMzMTN1+++1KSUnRmDFjQt08NBAmk8ln2zAMv7LaguCEOmfKlClatmyZVq1apRYtWoS6OajHNmzYoP3796tnz57espKSEq1atUpPP/20HA6HzGZzCFuI+iY5OVkdO3b0KevQoYPefPPNELUI9dlf//pXTZs2TVdffbUkqUuXLvrtt980c+ZMghNOuWbNmknyjDwlJyd7y/fv3+83ClVbcI4T6gzDMHTLLbforbfe0scff6w2bdqEukmo5y6++GJ9//33yszM9N7S0tJ07bXXKjMzk9CEk65fv35+l1nYunWrWrVqFaIWoT4rKChQWJjvr4Jms5nlyBEUbdq0UbNmzZSRkeEtczqdWrlypfr27RvCllWOESfUGTfffLMWL16s//73v4qJifHOjY2Li5Pdbg9x61AfxcTE+J1DFxUVpYSEBM6twylxxx13qG/fvnr00Uc1cuRIrV27Vs8//7yef/75UDcN9dDw4cP1yCOPqGXLlurUqZO++eYbzZ49W+PGjQt101BP5OXl6eeff/Zub9u2TZmZmYqPj1fLli11++2369FHH9Xpp5+u008/XY8++qgiIyN1zTXXhLDVlWM5ctQZlc13XbhwocaOHRvcxqDBuvDCC1mOHKfUO++8o+nTp+unn35SmzZtNHXqVE2cODHUzUI9lJubq/vuu09Lly7V/v37lZKSolGjRun++++X1WoNdfNQD3z66afq37+/X/mYMWOUnp4uwzA0Y8YMPffcczp8+LDOOeccPfPMM7X2j5MEJwAAAAAIgHOcAAAAACAAghMAAAAABEBwAgAAAIAACE4AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAqAGTyaS333471M0AAAQZwQkAUGeMHTtWJpPJ7zZ48OBQNw0AUM+Fh7oBAADUxODBg7Vw4UKfMpvNFqLWAAAaCkacAAB1is1mU7NmzXxujRs3luSZRjdv3jwNGTJEdrtdbdq00euvv+5z/Pfff6+LLrpIdrtdCQkJuvHGG5WXl+dTZ8GCBerUqZNsNpuSk5N1yy23+OzPzs7WZZddpsjISJ1++ulatmzZqX3TAICQIzgBAOqV++67T1dccYW+/fZbjR49WqNGjdKmTZskSQUFBRo8eLAaN26sdevW6fXXX9eHH37oE4zmzZunm2++WTfeeKO+//57LVu2TKeddprPa8yYMUMjR47Ud999p6FDh+raa6/VoUOHgvo+AQDBZTIMwwh1IwAAqI6xY8fqpZdeUkREhE/53Xffrfvuu08mk0mTJk3SvHnzvPt69+6tHj16aO7cufr3v/+tu+++Wzt37lRUVJQkafny5Ro+fLj27NmjpKQkNW/eXDfccIP+/ve/V9gGk8mkv/3tb3r44YclSfn5+YqJidHy5cs51woA6jHOcQIA1Cn9+/f3CUaSFB8f733cp08fn319+vRRZmamJGnTpk3q1q2bNzRJUr9+/eR2u7VlyxaZTCbt2bNHF198cZVt6Nq1q/dxVFSUYmJitH///t/7lgAAdQDBCQBQp0RFRflNnQvEZDJJkgzD8D6uqI7dbq/W81ksFr9j3W53jdoEAKhbOMcJAFCvfPnll37bZ555piSpY8eOyszMVH5+vnf/559/rrCwMJ1xxhmKiYlR69at9dFHHwW1zQCA2o8RJwBAneJwOLR3716fsvDwcCUmJkqSXn/9daWlpencc8/Vyy+/rLVr12r+/PmSpGuvvVYPPPCAxowZowcffFAHDhzQlClTdN111ykpKUmS9OCDD2rSpElq2rSphgwZotzcXH3++eeaMmVKcN8oAKBWITgBAOqU9957T8nJyT5l7du31+bNmyV5Vrx79dVXNXnyZDVr1kwvv/yyOnbsKEmKjIzU+++/r9tuu029evVSZGSkrrjiCs2ePdv7XGPGjFFRUZGefPJJ3XnnnUpMTNSVV14ZvDcIAKiVWFUPAFBvmEwmLV26VCNGjAh1UwAA9QznOAEAAABAAAQnAAAAAAiAc5wAAPUGs88BAKcKI04AAAAAEADBCQAAAAACIDgBAAAAQAAEJwAAAAAIgOAEAAAAAAEQnAAAAAAgAIITAAAAAARAcAIAAACAAP4fTOlM3zXvK4UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_og = losses\n",
    "accuracies_og = accuracies\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "original_accuracy = 100 * correct / total\n",
    "print(f\"Original Accuracy: {original_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662acc69-3385-4c7b-9969-78aa3a91cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1071, Accuracy: 0.4852\n",
      "Epoch 2, Loss: 1.0518, Accuracy: 0.5099\n"
     ]
    }
   ],
   "source": [
    "# Test with 5x5 blur augmentation\n",
    "Xmat_train = apply_blur(Xmat_train_og, (5,5))\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "num_epochs_blur5 = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "blur5_accuracies = accuracies\n",
    "blur5_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bfecc-d550-401a-b765-a60ed1289fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "blur5_accuracy = 100 * correct / total\n",
    "print(f\"Blur 5 Accuracy: {blur5_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Blur 5: Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3154558-dde1-46a0-abbf-a091f85516ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 15x15 blur augmentation\n",
    "Xmat_train = apply_blur(Xmat_train_og, (15,15))\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "print(\"Augmentation completed\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Begin training\")\n",
    "\n",
    "num_epochs = 5\n",
    "num_epochs_blur15 = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "blur15_accuracies = accuracies\n",
    "blur15_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da82f31-fd25-4bfe-9604-692f0fc541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "blur15_accuracy = 100 * correct / total\n",
    "print(f\"Blur 15 Accuracy: {blur15_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Blur 15: Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a519e-bd6b-43c0-92fc-5e6d2a14c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 25x25 blur augmentation\n",
    "Xmat_train = apply_blur(Xmat_train_og, (25,25))\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "print(\"Augmentation completed\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Begin training\")\n",
    "\n",
    "num_epochs = 5\n",
    "num_epochs_blur25 = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "blur25_accuracies = accuracies\n",
    "blur25_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8456e-4700-4ebd-a998-65264d04ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "blur25_accuracy = 100 * correct / total\n",
    "print(f\"Blur 25 Accuracy: {blur15_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Blur 25: Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78213c3a-9b83-48c6-b127-e587a79fe0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with greyscale augmentation\n",
    "Xmat_train = apply_greyscale(Xmat_train_og)\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "num_epochs_greyscale = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "grey_accuracies = accuracies\n",
    "grey_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e80ae4-238d-409e-b738-b819b2523c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "grey_accuracy = 100 * correct / total\n",
    "print(f\"Greyscale Accuracy: {grey_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Greyscale: Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d22e4-08e5-4eed-b902-cefd705ccf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b6b29-8174-45f4-81ca-a42e2c67ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with contrast 0.5 augmentation\n",
    "Xmat_train = adjust_contrast(Xmat_train_og, 0.5)\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "num_epochs_contrast05 = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "contrast05_accuracies = accuracies\n",
    "contrast05_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d660d-8cf1-4eb2-baef-df3c6e3c9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "contrast05_accuracy = 100 * correct / total\n",
    "print(f\"Contrast 0.5 Accuracy: {contrast05_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Contrast 0.5: Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1050f-6cf3-48d0-adcf-c560e499bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with contrast 1.5 augmentation\n",
    "Xmat_train = adjust_contrast(Xmat_train_og, 1.5)\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "num_epochs_contrast15 = num_epochs\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = outputs.max(1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "contrast15_accuracies = accuracies\n",
    "contrast15_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06f77e-f2f6-4faf-8b13-410d8b33bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "contrast15_accuracy = 100 * correct / total\n",
    "print(f\"Contrast 1.5 Accuracy: {contrast15_accuracy:.2f}%\")\n",
    "\n",
    "# After training, plot loss and accuracy graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), losses, label='Loss')\n",
    "plt.plot(range(1, num_epochs+1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Contrast 1.5: Loss and Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95517c8-c47b-4389-98f8-19df6086987c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cf67b-1ac3-43d8-b0dd-ff3cd59bd96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373403e-f114-442e-a500-603cd4090089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a46b7a-4aa8-4f84-960c-f6f4bee64fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbfce4-91c8-4164-b2df-3ef5d7ce0bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
