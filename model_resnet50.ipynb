{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c2ef70-6377-46d7-a5d5-3e647409034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fff558-b739-498f-ab22-4e38262374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/100\"\n",
    "\n",
    "# Get tumour file paths and shuffle\n",
    "tumour_files = []\n",
    "tumour_dirs = [\n",
    "    \"Invasive_Tumor\",\n",
    "    \"Prolif_Invasive_Tumor\",\n",
    "    \"T_Cell_and_Tumor_Hybrid\"\n",
    "]\n",
    "\n",
    "for dir_name in tumour_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        tumour_files.extend(files)\n",
    "\n",
    "random.shuffle(tumour_files)\n",
    "\n",
    "# Get immune file paths and shuffle\n",
    "immune_files = []\n",
    "immune_dirs = [\n",
    "    \"CD4+_T_Cells\", \"CD4+_T_Cells\", \n",
    "    \"CD8+_T_Cells\", \n",
    "    \"B_Cells\", \n",
    "    \"Mast_Cells\", \n",
    "    \"Macrophages_1\", \n",
    "    \"Macrophages_2\", \n",
    "    \"LAMP3+_DCs\",\n",
    "    \"IRF7+_DCs\"\n",
    "]\n",
    "\n",
    "for dir_name in immune_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        immune_files.extend(files)\n",
    "\n",
    "random.shuffle(immune_files)\n",
    "\n",
    "\n",
    "# Get stromal file paths and shuffle\n",
    "stromal_files = []\n",
    "stromal_dirs = [\n",
    "    \"Stromal\", \n",
    "    \"Stromal_and_T_Cell_Hybrid\", \n",
    "    \"Perivascular-Like\"\n",
    "]\n",
    "\n",
    "for dir_name in stromal_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        stromal_files.extend(files)\n",
    "\n",
    "random.shuffle(stromal_files)\n",
    "\n",
    "# Get other file paths and shuffle\n",
    "other_files = []\n",
    "other_dirs = [\n",
    "    \"Endothelial\",\n",
    "    \"Myoepi_ACTA2+\", \n",
    "    \"Myoepi_KRT15+\", \n",
    "    \"DCIS_1\", \n",
    "    \"DCIS_2\", \n",
    "    \"Unlabeled\"\n",
    "]\n",
    "\n",
    "for dir_name in stromal_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        other_files.extend(files)\n",
    "\n",
    "random.shuffle(other_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ce502b-23f9-48ff-95d8-453f1252b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize(img_path, size=(224,224)):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(size)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90906d4-8da0-47a4-b5a6-b85a7b4f2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumour_imgs = [load_resize(f) for f in tumour_files]\n",
    "print(\"tumour loaded\")\n",
    "\n",
    "immune_imgs = [load_resize(f) for f in immune_files]\n",
    "print(\"immune loaded\")\n",
    "\n",
    "stromal_imgs = [load_resize(f) for f in stromal_files]\n",
    "print(\"stromal loaded\")\n",
    "\n",
    "other_imgs = [load_resize(f) for f in other_files]\n",
    "print(\"other loaded\")\n",
    "\n",
    "# Train using 80% of data from each group\n",
    "'''\n",
    "tumour_train_ind = int(0.8 * len(tumour_imgs))\n",
    "tumour_test_ind = int(0.2 * len(tumour_imgs))\n",
    "\n",
    "immune_train_ind = int(0.8 * len(immune_imgs))\n",
    "immune_test_ind = int(0.2 * len(immune_imgs))\n",
    "\n",
    "stromal_train_ind = int(0.8 * len(stromal_imgs))\n",
    "stromal_test_ind = int(0.2 * len(stromal_imgs))\n",
    "\n",
    "other_train_ind = int(0.8 * len(other_imgs))\n",
    "other_test_ind = int(0.2 * len(other_imgs))\n",
    "'''\n",
    "\n",
    "tumour_train_ind = 2000\n",
    "tumour_test_ind = 500\n",
    "\n",
    "immune_train_ind = 2000\n",
    "immune_test_ind = 500\n",
    "\n",
    "stromal_train_ind = 2000\n",
    "stromal_test_ind = 500\n",
    "\n",
    "other_train_ind = 2000\n",
    "other_test_ind = 500\n",
    "\n",
    "imgs_train = immune_imgs[:immune_train_ind] + tumour_imgs[:tumour_train_ind] + stromal_imgs[:stromal_train_ind] + other_imgs[:other_train_ind]\n",
    "imgs_test = immune_imgs[immune_train_ind:] + tumour_imgs[tumour_train_ind:] + stromal_imgs[stromal_train_ind:] + other_imgs[other_train_ind:]\n",
    "\n",
    "Xmat_train = np.stack(imgs_train, axis=0)\n",
    "Xmat_test = np.stack(imgs_test, axis=0)\n",
    "\n",
    "y_train = ['Immune'] * immune_train_ind + ['Tumour'] * tumour_train_ind + ['Stromal'] * stromal_train_ind + ['Other'] * other_train_ind\n",
    "y_test = ['Immune'] * immune_test_ind + ['Tumour'] * tumour_test_ind + ['Stromal'] * stromal_test_ind + ['Other'] * other_test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994753b-e75e-41a3-9b80-5eaf4279467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cbd41-b0a6-42ba-8dd5-ad8699c16cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        image = Image.fromarray((image * 255).astype('uint8'))  # Convert to PIL Image\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036590c-ab81-4c41-ad21-6d287254dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = NumpyImageDataset(Xmat_train, y_train_enc, transform=transform)\n",
    "test_dataset = NumpyImageDataset(Xmat_test, y_test_enc, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb765ed5-738d-4473-9260-9f5c49decc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17611a1-d45e-44a9-8682-4d58adbe2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7d45e-ccac-4a46-9189-34009dc8d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3838d-cb4b-4dd7-a11d-4c60d3f63da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662acc69-3385-4c7b-9969-78aa3a91cb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e494dbd-3f22-49b0-be54-05f399157aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3154558-dde1-46a0-abbf-a091f85516ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53198cf4-1ac6-48b1-a43e-7c6860b9f80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
