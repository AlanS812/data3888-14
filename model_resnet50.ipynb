{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c2ef70-6377-46d7-a5d5-3e647409034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45fff558-b739-498f-ab22-4e38262374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/100\"\n",
    "\n",
    "# Get tumour file paths and shuffle\n",
    "tumour_files = []\n",
    "tumour_dirs = [\n",
    "    \"Invasive_Tumor\",\n",
    "    \"Prolif_Invasive_Tumor\",\n",
    "    \"T_Cell_and_Tumor_Hybrid\"\n",
    "]\n",
    "\n",
    "for dir_name in tumour_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        tumour_files.extend(files)\n",
    "\n",
    "random.shuffle(tumour_files)\n",
    "\n",
    "# Get immune file paths and shuffle\n",
    "immune_files = []\n",
    "immune_dirs = [\n",
    "    \"CD4+_T_Cells\", \"CD4+_T_Cells\", \n",
    "    \"CD8+_T_Cells\", \n",
    "    \"B_Cells\", \n",
    "    \"Mast_Cells\", \n",
    "    \"Macrophages_1\", \n",
    "    \"Macrophages_2\", \n",
    "    \"LAMP3+_DCs\",\n",
    "    \"IRF7+_DCs\"\n",
    "]\n",
    "\n",
    "for dir_name in immune_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        immune_files.extend(files)\n",
    "\n",
    "random.shuffle(immune_files)\n",
    "\n",
    "\n",
    "# Get stromal file paths and shuffle\n",
    "stromal_files = []\n",
    "stromal_dirs = [\n",
    "    \"Stromal\", \n",
    "    \"Stromal_and_T_Cell_Hybrid\", \n",
    "    \"Perivascular-Like\"\n",
    "]\n",
    "\n",
    "for dir_name in stromal_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        stromal_files.extend(files)\n",
    "\n",
    "random.shuffle(stromal_files)\n",
    "\n",
    "# Get other file paths and shuffle\n",
    "other_files = []\n",
    "other_dirs = [\n",
    "    \"Endothelial\",\n",
    "    \"Myoepi_ACTA2+\", \n",
    "    \"Myoepi_KRT15+\", \n",
    "    \"DCIS_1\", \n",
    "    \"DCIS_2\", \n",
    "    \"Unlabeled\"\n",
    "]\n",
    "\n",
    "for dir_name in stromal_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        other_files.extend(files)\n",
    "\n",
    "random.shuffle(other_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ce502b-23f9-48ff-95d8-453f1252b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize(img_path, size=(224,224)):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(size)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90906d4-8da0-47a4-b5a6-b85a7b4f2363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumour loaded\n",
      "immune loaded\n",
      "stromal loaded\n",
      "other loaded\n"
     ]
    }
   ],
   "source": [
    "tumour_imgs = [load_resize(f) for f in tumour_files]\n",
    "print(\"tumour loaded\")\n",
    "\n",
    "immune_imgs = [load_resize(f) for f in immune_files]\n",
    "print(\"immune loaded\")\n",
    "\n",
    "stromal_imgs = [load_resize(f) for f in stromal_files]\n",
    "print(\"stromal loaded\")\n",
    "\n",
    "other_imgs = [load_resize(f) for f in other_files]\n",
    "print(\"other loaded\")\n",
    "\n",
    "# Train using 80% of data from each group\n",
    "'''\n",
    "tumour_train_ind = int(0.8 * len(tumour_imgs))\n",
    "tumour_test_ind = int(0.2 * len(tumour_imgs))\n",
    "\n",
    "immune_train_ind = int(0.8 * len(immune_imgs))\n",
    "immune_test_ind = int(0.2 * len(immune_imgs))\n",
    "\n",
    "stromal_train_ind = int(0.8 * len(stromal_imgs))\n",
    "stromal_test_ind = int(0.2 * len(stromal_imgs))\n",
    "\n",
    "other_train_ind = int(0.8 * len(other_imgs))\n",
    "other_test_ind = int(0.2 * len(other_imgs))\n",
    "'''\n",
    "\n",
    "tumour_train_ind = 1000\n",
    "tumour_test_ind = 1200\n",
    "\n",
    "immune_train_ind = 1000\n",
    "immune_test_ind = 1200\n",
    "\n",
    "stromal_train_ind = 1000\n",
    "stromal_test_ind = 1200\n",
    "\n",
    "other_train_ind = 1000\n",
    "other_test_ind = 1200\n",
    "\n",
    "imgs_train = immune_imgs[:immune_train_ind] + tumour_imgs[:tumour_train_ind] + stromal_imgs[:stromal_train_ind] + other_imgs[:other_train_ind]\n",
    "imgs_test = immune_imgs[immune_train_ind:immune_test_ind] + tumour_imgs[tumour_train_ind:tumour_test_ind] + stromal_imgs[stromal_train_ind:stromal_test_ind] + other_imgs[other_train_ind:other_test_ind]\n",
    "\n",
    "Xmat_train = np.stack(imgs_train, axis=0)\n",
    "Xmat_test = np.stack(imgs_test, axis=0)\n",
    "\n",
    "y_train = ['Immune'] * immune_train_ind + ['Tumour'] * tumour_train_ind + ['Stromal'] * stromal_train_ind + ['Other'] * other_train_ind\n",
    "y_test = ['Immune'] * immune_test_ind + ['Tumour'] * tumour_test_ind + ['Stromal'] * stromal_test_ind + ['Other'] * other_test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b984db-ba83-4a27-a685-69fce077f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blur(images):\n",
    "    return np.array([cv2.GaussianBlur(img, (5, 5), 0) for img in images])\n",
    "\n",
    "def apply_stretch(images):\n",
    "    stretched = []\n",
    "    for img in images:\n",
    "        h, w, c = img.shape\n",
    "        new_w = int(w * 1.2)  # stretch width by 20%\n",
    "        img_stretched = cv2.resize(img, (new_w, h))\n",
    "        img_cropped = img_stretched[:, :w, :]  # crop back to original width\n",
    "        stretched.append(img_cropped)\n",
    "    return np.array(stretched)\n",
    "\n",
    "def apply_greyscale(images):\n",
    "    greyscale = []\n",
    "    for img in images:\n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        grey_3ch = cv2.cvtColor(grey, cv2.COLOR_GRAY2RGB)\n",
    "        greyscale.append(grey_3ch)\n",
    "    return np.array(greyscale)\n",
    "\n",
    "def apply_rotation(images):\n",
    "    rotated = []\n",
    "    for img in images:\n",
    "        (h, w) = img.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        matrix = cv2.getRotationMatrix2D(center, 15, 1.0)  # rotate 15 degrees\n",
    "        rotated_img = cv2.warpAffine(img, matrix, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "        rotated.append(rotated_img)\n",
    "    return np.array(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f5dc3-f05f-4633-9c30-49da85c7e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmat_train_original = Xmat_train\n",
    "Xmat_train_blur = apply_blur(Xmat_train)\n",
    "Xmat_train_stretch = apply_stretch(Xmat_train)\n",
    "Xmat_train_greyscale = apply_greyscale(Xmat_train)\n",
    "Xmat_train_rotate = apply_rotation(Xmat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d994753b-e75e-41a3-9b80-5eaf4279467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338cbd41-b0a6-42ba-8dd5-ad8699c16cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        image = Image.fromarray((image * 255).astype('uint8'))  # Convert to PIL Image\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5036590c-ab81-4c41-ad21-6d287254dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = NumpyImageDataset(Xmat_train_original, y_train_enc, transform=transform)\n",
    "test_dataset = NumpyImageDataset(Xmat_test, y_test_enc, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb765ed5-738d-4473-9260-9f5c49decc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/jason/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████████████████████████████████| 44.7M/44.7M [00:07<00:00, 6.06MB/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "K.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17611a1-d45e-44a9-8682-4d58adbe2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a7d45e-ccac-4a46-9189-34009dc8d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2882\n",
      "Epoch 2, Loss: 1.1134\n",
      "Epoch 3, Loss: 1.0648\n",
      "Epoch 4, Loss: 1.0473\n",
      "Epoch 5, Loss: 1.0250\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0b3838d-cb4b-4dd7-a11d-4c60d3f63da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 15.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Original Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662acc69-3385-4c7b-9969-78aa3a91cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with blur augmentation\n",
    "train_dataset = NumpyImageDataset(Xmat_train_blur, y_train_enc, transform=transform)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "K.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e494dbd-3f22-49b0-be54-05f399157aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bfecc-d550-401a-b765-a60ed1289fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Blur Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3154558-dde1-46a0-abbf-a091f85516ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with stretch augmentation\n",
    "train_dataset = NumpyImageDataset(Xmat_train_stretch, y_train_enc, transform=transform)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "K.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53198cf4-1ac6-48b1-a43e-7c6860b9f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da82f31-fd25-4bfe-9604-692f0fc541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Stretch Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eea16a-1edd-4dd3-bd53-b41250062bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with greyscale augmentation\n",
    "train_dataset = NumpyImageDataset(Xmat_train_greyscale, y_train_enc, transform=transform)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "K.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94430e4-7684-4390-a4bd-21a5ff1482e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98208839-d7b4-4526-9d0c-6939a5d3aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Greyscale Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1f4a2-8e2c-47f8-a408-19670cc53fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with rotate augmentation\n",
    "train_dataset = NumpyImageDataset(Xmat_train_rotate, y_train_enc, transform=transform)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "K.clear_session()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf8b31-65af-4d34-96d6-ac5a42272f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020de96-e314-45b9-b7af-3d4ed0887867",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Pick class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Rotation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d22e4-08e5-4eed-b902-cefd705ccf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
