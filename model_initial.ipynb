{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ae30b-bdb1-4069-9412-f2f7fcd4ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233c2e3-83ca-4dc4-8bf5-522b7dabd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image file paths and shuffle\n",
    "tumour_files = os.listdir(\"data/100/Invasive_Tumor/\")\n",
    "tumour_files = [os.path.join(\"data/100/Invasive_Tumor/\", f) for f in tumour_files]\n",
    "random.shuffle(tumour_files)\n",
    "\n",
    "immune_files = os.listdir(\"data/100/CD8+_T_Cells/\")\n",
    "immune_files = [os.path.join(\"data/100/CD8+_T_Cells/\", f) for f in immune_files]\n",
    "random.shuffle(immune_files)\n",
    "\n",
    "other_files = os.listdir(\"data/100/Myoepi_ACTA2+/\")\n",
    "other_files = [os.path.join(\"data/100/Myoepi_ACTA2+/\", f) for f in other_files]\n",
    "random.shuffle(other_files)\n",
    "\n",
    "print(len(tumour_files))\n",
    "print(len(immune_files))\n",
    "print(len(other_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d312d-7581-4d48-8850-75b3a9fd5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize(img_path, size=(50,50)):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(size)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf7c33-35fc-4949-9075-837cf2cd5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumour_imgs = [load_resize(f) for f in tumour_files]\n",
    "immune_imgs = [load_resize(f) for f in immune_files]\n",
    "other_imgs = [load_resize(f) for f in other_files]\n",
    "\n",
    "imgs_train = immune_imgs[:5000] + tumour_imgs[:5000] + other_imgs[:5000]\n",
    "imgs_test = immune_imgs[5000:6000] + tumour_imgs[5000:6000] + other_imgs[5000:6000]\n",
    "\n",
    "Xmat_train = np.stack(imgs_train, axis=0)\n",
    "Xmat_test = np.stack(imgs_test, axis=0)\n",
    "\n",
    "y_train = ['Immune'] * 5000 + ['Tumour'] * 5000 + ['Other'] * 5000\n",
    "y_test = ['Immune'] * 1000 + ['Tumour'] * 1000 + ['Other'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c71a5c-9730-4ef6-85d4-7979b03eccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (50, 50, 3)\n",
    "\n",
    "def model_function(learning_rate=0.00001):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (5, 5), activation=None, input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(32, (5, 5), activation=None))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=None))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation=None))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb127b5-8f20-4e82-8a14-8ce078f32320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin Model Construction\")\n",
    "\n",
    "# Create the model\n",
    "model = model_function()\n",
    "model.summary()\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "num_images = Xmat_train.shape[0]\n",
    "yMat = pd.get_dummies(y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4c2c2-259e-4823-a515-37ae180766f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin Model Training\")\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x = Xmat_train,\n",
    "    y = yMat,\n",
    "    batch_size=batch_size,\n",
    "    # steps_per_epoch = int(len(Xmat_train) / batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose =2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0e11d-9e18-4d43-9395-406b9f91e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot (only if accuracy metric was included in model.compile)\n",
    "if 'accuracy' in history.history:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e9b5e-e87b-47dd-bea9-a462eb11a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "pred_CNN_prob = model.predict(Xmat_test)\n",
    "\n",
    "# Convert probabilities to predicted class labels\n",
    "pred_CNN_indices = np.argmax(pred_CNN_prob, axis=1)\n",
    "pred_CNN = np.array(['Immune', 'Tumour', 'Other'])[pred_CNN_indices]\n",
    "\n",
    "# Create confusion matrix\n",
    "tab = confusion_matrix(y_test, pred_CNN, labels=['Immune', 'Tumour', 'Other'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tab)\n",
    "\n",
    "accuracy = np.trace(tab) / np.sum(tab)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72050a23-066e-47b5-818b-ec6ba1910305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5eef0-f347-49fa-b6f7-0c0354e98a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
