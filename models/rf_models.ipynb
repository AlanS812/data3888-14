{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea86941-c4ed-44fc-b39a-e1aa4c01c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes - visualisations for report?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c4313-89ae-498a-b829-8ad29c17cc95",
   "metadata": {},
   "source": [
    "## RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e03bf5-9b67-48fc-885d-e541439354e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image counts:\n",
      "  Tumour: 38763\n",
      "  Immune: 42598\n",
      "  Stromal: 42878\n",
      "  Other: 43519\n",
      "After label_and_split:\n",
      "  Tumour split: 2500 500 3000\n",
      "  Immune split: 2500 500 3000\n",
      "  Stromal split: 2500 500 3000\n",
      "  Other split: 2500 500 3000\n",
      "[('Immune', 0), ('Other', 1), ('Stromal', 2), ('Tumour', 3)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'evaluation')))\n",
    "import data_preprocessing\n",
    "\n",
    "#import importlib\n",
    "#importlib.reload(data_preprocessing)\n",
    "#print(\"[DEBUG] Loaded from:\", data_preprocessing.__file__)\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# suppress warnings for results\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "Xmat_train, Xmat_val, Xmat_tests_0, Xmat_tests_1, Xmat_tests_2, y_train_enc, y_val_enc, y_tests_enc_0, y_tests_enc_1, y_tests_enc_2 = data_preprocessing.load_split_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da01934-a22e-4c84-8535-5593065b5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running evaluations on test set: 0\n",
      "Evaluating baseline (no blur, no noise)...\n",
      "Model: base\n",
      "Model: pca\n",
      "Model: hog\n",
      "Evaluating blur=0, noise=0...\n",
      "Model: base\n",
      "Model: pca\n",
      "Model: hog\n",
      "Evaluating blur=1, noise=0...\n",
      "Model: base\n",
      "Model: pca\n",
      "Model: hog\n"
     ]
    }
   ],
   "source": [
    "def store_results(results, y_true, y_pred, probs=None, blur=0, noise=0, hog=False, pca=False, **extra_metrics):        \n",
    "    entry = {\n",
    "        \"blur_size\": blur,\n",
    "        \"noise_level\": noise,\n",
    "        \"HOG\": hog,\n",
    "        \"PCA\": pca,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "    }\n",
    "\n",
    "    f1_classes = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    precision_classes = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall_classes = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    label_map = {\n",
    "        0: \"immune\",\n",
    "        1: \"other\",\n",
    "        2: \"stromal\",\n",
    "        3: \"tumour\"\n",
    "    }\n",
    "    \n",
    "    for i in range(4):\n",
    "        label = label_map[i]\n",
    "        entry[f\"f1_{label}\"] = f1_classes[i]\n",
    "        entry[f\"precision_{label}\"] = precision_classes[i]\n",
    "        entry[f\"recall_{label}\"] = recall_classes[i]\n",
    "    \n",
    "    if probs is not None:\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        entry[\"confidence_overall\"] = np.mean(confidences)\n",
    "        for cls in range(4):\n",
    "            label = label_map[cls]\n",
    "            cls_conf = confidences[y_pred == cls]\n",
    "            entry[f\"confidence_{label}_avg\"] = np.mean(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "            entry[f\"confidence_{label}_std\"] = np.std(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "    \n",
    "    total_preds = len(y_pred)\n",
    "    for cls in range(4):\n",
    "        label = label_map[cls]\n",
    "        entry[f\"count_pred_{label}\"] = np.sum(y_pred == cls)\n",
    "\n",
    "    # store actual and predicted labels and the confusion matrix as strings\n",
    "    entry[\"confusion_matrix\"] = str(confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3]).tolist())\n",
    "\n",
    "    entry.update(extra_metrics)\n",
    "    results.append(entry)\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        if img.shape[-1] == 3:\n",
    "            img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"L\")\n",
    "            img = np.array(img)\n",
    "        features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# preprocessing\n",
    "X_train_flat = Xmat_train.reshape(Xmat_train.shape[0], -1)\n",
    "X_val_flat = Xmat_val.reshape(Xmat_val.shape[0], -1)\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "X_train_hog = extract_hog_features(Xmat_train)\n",
    "\n",
    "# fitting models\n",
    "model_base = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_base.fit(X_train_flat, y_train_enc)\n",
    "\n",
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_pca.fit(X_train_pca, y_train_enc)\n",
    "\n",
    "model_hog = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_hog.fit(X_train_hog, y_train_enc)\n",
    "\n",
    "# helper functions, model map\n",
    "def evaluate_and_store(model, X, y_true, model_label, test_set, probs=True, **kwargs):\n",
    "    y_pred = model.predict(X)\n",
    "    y_probs = model.predict_proba(X) if probs else None\n",
    "    store_results(results, y_true, y_pred, probs=y_probs, model_label=model_label, test_set=test_set, **kwargs)\n",
    "\n",
    "models = {\n",
    "    \"base\": (model_base, lambda X: X.reshape(X.shape[0], -1), {}),\n",
    "    \"pca\": (model_pca, lambda X: pca.transform(X.reshape(X.shape[0], -1)), {\"pca\": True}),\n",
    "    \"hog\": (model_hog, extract_hog_features, {\"hog\": True}),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def run_all_variants(X_base, y_base, test_set_name):\n",
    "    blur_levels = [0, 1, 3, 5, 7, 9, 19]\n",
    "    noise_levels = [0, 1, 3, 5, 10, 20, 30]\n",
    "\n",
    "    # Unmodified input (baseline)\n",
    "    print(\"Evaluating baseline (no blur, no noise)...\")\n",
    "    for name, (model, transform, flags) in models.items():\n",
    "        print(f\"Model: {name}\")\n",
    "        X_trans = transform(X_base)\n",
    "        evaluate_and_store(\n",
    "            model,\n",
    "            X_trans,\n",
    "            y_base,\n",
    "            model_label=name.upper(),\n",
    "            test_set=test_set_name,\n",
    "            blur=0,\n",
    "            noise=0,\n",
    "            **flags\n",
    "        )\n",
    "\n",
    "    # Blur only\n",
    "    for blur in blur_levels:\n",
    "        print(f\"Evaluating blur={blur}, noise=0...\")\n",
    "        X_blur = data_preprocessing.apply_blur(X_base, blur)\n",
    "        for name, (model, transform, flags) in models.items():\n",
    "            print(f\"Model: {name}\")\n",
    "            X_trans = transform(X_blur)\n",
    "            evaluate_and_store(\n",
    "                model,\n",
    "                X_trans,\n",
    "                y_base,\n",
    "                model_label=name.upper(),\n",
    "                test_set=test_set_name,\n",
    "                blur=blur,\n",
    "                noise=0,\n",
    "                **flags\n",
    "            )\n",
    "\n",
    "    # Noise only\n",
    "    for noise in noise_levels:\n",
    "        print(f\"Evaluating blur=0, noise={noise}...\")\n",
    "        np.random.seed(3888 + noise)\n",
    "        X_noisy = data_preprocessing.apply_noise(X_base, std=noise)\n",
    "        for name, (model, transform, flags) in models.items():\n",
    "            print(f\"Model: {name}\")\n",
    "            X_trans = transform(X_noisy)\n",
    "            evaluate_and_store(\n",
    "                model,\n",
    "                X_trans,\n",
    "                y_base,\n",
    "                model_label=name.upper(),\n",
    "                test_set=test_set_name,\n",
    "                blur=0,\n",
    "                noise=noise,\n",
    "                **flags\n",
    "            )\n",
    "\n",
    "    # Blur + noise \n",
    "    for blur in blur_levels:\n",
    "        for noise in noise_levels:\n",
    "            print(f\"Evaluating blur={blur}, noise={noise}...\")\n",
    "            np.random.seed(10000 + blur * 100 + noise)\n",
    "            X_blur = data_preprocessing.apply_blur(X_base, blur)\n",
    "            X_combo = data_preprocessing.apply_noise(X_blur, std=noise)\n",
    "            for name, (model, transform, flags) in models.items():\n",
    "                print(f\"Model: {name}\")\n",
    "                X_trans = transform(X_combo)\n",
    "                evaluate_and_store(\n",
    "                    model,\n",
    "                    X_trans,\n",
    "                    y_base,\n",
    "                    model_label=name.upper(),\n",
    "                    test_set=test_set_name,\n",
    "                    blur=blur,\n",
    "                    noise=noise,\n",
    "                    **flags\n",
    "                )\n",
    "\n",
    "test_sets = [\n",
    "    (0, Xmat_tests_0, y_tests_enc_0),\n",
    "    (1, Xmat_tests_1, y_tests_enc_1),\n",
    "    (2, Xmat_tests_2, y_tests_enc_2),\n",
    "]\n",
    "\n",
    "for name, X, y in test_sets:\n",
    "    print(f\"\\nRunning evaluations on test set: {name}\")\n",
    "    run_all_variants(X, y, test_set_name=name)\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # this file's folder\n",
    "METRICS_PATH = os.path.join(BASE_DIR, \"..\", \"metrics\", \"rf_augmented_metrics.csv\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(METRICS_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
