{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88c4313-89ae-498a-b829-8ad29c17cc95",
   "metadata": {},
   "source": [
    "# RF PCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca04dd8-a6fd-4309-8d90-d2dd5047af11",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2063ed4-166c-4293-8692-b2f33f7edb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Immune', 0), ('Other', 1), ('Stromal', 2), ('Tumour', 3)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import data_preprocessing\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# 0 Immune, 1 Other, 2 Stromal, 3 Tumour\n",
    "Xmat_train, Xmat_val, Xmat_tests_0, Xmat_tests_1, Xmat_tests_2, y_train_enc, y_val_enc, y_tests_enc_0, y_tests_enc_1, y_tests_enc_2 = data_preprocessing.load_split_images()\n",
    "\n",
    "# reassigning to just use first one for shiny\n",
    "Xmat_test = Xmat_tests_0\n",
    "y_test_enc = y_tests_enc_0\n",
    "\n",
    "def store_results(results, y_true, y_pred, probs=None, blur=0, noise=0, hog=False, pca=False, **extra_metrics):        \n",
    "    entry = {\n",
    "        \"blur_size\": blur,\n",
    "        \"noise_level\": noise,\n",
    "        #\"HOG\": hog,\n",
    "        #\"PCA\": pca, # only doing the PCA one for shiny\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "    }\n",
    "\n",
    "    f1_classes = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    precision_classes = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall_classes = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    label_map = {\n",
    "        0: \"immune\",\n",
    "        1: \"other\",\n",
    "        2: \"stromal\",\n",
    "        3: \"tumour\"\n",
    "    }\n",
    "    \n",
    "    for i in range(4):\n",
    "        label = label_map[i]\n",
    "        entry[f\"f1_{label}\"] = f1_classes[i]\n",
    "        entry[f\"precision_{label}\"] = precision_classes[i]\n",
    "        entry[f\"recall_{label}\"] = recall_classes[i]\n",
    "    \n",
    "    if probs is not None:\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        entry[\"confidence_overall\"] = np.mean(confidences)\n",
    "        for cls in range(4):\n",
    "            label = label_map[cls]\n",
    "            cls_conf = confidences[y_pred == cls]\n",
    "            entry[f\"confidence_{label}_avg\"] = np.mean(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "            entry[f\"confidence_{label}_std\"] = np.std(cls_conf) if len(cls_conf) > 0 else np.nan\n",
    "    \n",
    "    total_preds = len(y_pred)\n",
    "    for cls in range(4):\n",
    "        label = label_map[cls]\n",
    "        entry[f\"count_pred_{label}\"] = np.sum(y_pred == cls)\n",
    "\n",
    "    # Store actual and predicted labels and the confusion matrix as strings\n",
    "    entry[\"confusion_matrix\"] = str(confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3]).tolist())\n",
    "\n",
    "    entry.update(extra_metrics)\n",
    "    results.append(entry)\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        if img.shape[-1] == 3:\n",
    "            img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"L\")\n",
    "            img = np.array(img)\n",
    "        features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# use shiny version (the same but cleaner), and same for hog thing if possible?\n",
    "def apply_noise(images, mean=0, std=10, seed=3888):\n",
    "    if std > 0:\n",
    "        np.random.seed(seed)  # Consistent noise for all images in this batch\n",
    "        noise = np.random.normal(mean, std, images.shape)\n",
    "        noisy_images = images + noise\n",
    "        noisy_images = np.clip(noisy_images, 0, 255).astype(np.uint8)\n",
    "        return noisy_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "X_train_flat = Xmat_train.reshape(Xmat_train.shape[0], -1)\n",
    "X_val_flat   = Xmat_val.reshape(Xmat_val.shape[0], -1)\n",
    "X_test_flat  = Xmat_test.reshape(Xmat_test.shape[0], -1)\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421dca65-206b-4ba2-8948-a5f6ec23c887",
   "metadata": {},
   "source": [
    "## RF PCA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c49c7b52-0d43-4447-80e1-fa1190ceb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_pca.fit(X_train_pca, y_train_enc)\n",
    "\n",
    "# baseline\n",
    "X_test_pca = pca.transform(X_test_flat)\n",
    "y_pred = model_pca.predict(X_test_pca)\n",
    "y_probs = model_pca.predict_proba(X_test_pca)\n",
    "store_results(results, y_test_enc, y_pred, probs=y_probs)\n",
    "\n",
    "for radius in [1, 3, 5, 7, 9, 19]: # blur\n",
    "    X_blur = data_preprocessing.apply_blur(Xmat_test, radius)\n",
    "    X_test_flat = X_blur.reshape(X_blur.shape[0], -1)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    y_pred = model_pca.predict(X_test_pca)\n",
    "    y_probs = model_pca.predict_proba(X_test_pca)\n",
    "    store_results(results, y_test_enc, y_pred, blur=radius, probs=y_probs)\n",
    "\n",
    "for noise_std in [1, 3, 5, 10, 20, 30]:\n",
    "    seed = 3888 + noise_std  # same seed logic as baseline\n",
    "    X_noisy = apply_noise(Xmat_test, std=noise_std, seed=seed)\n",
    "    X_test_flat = X_noisy.reshape(X_noisy.shape[0], -1)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "    y_pred = model_pca.predict(X_test_pca)\n",
    "    y_probs = model_pca.predict_proba(X_test_pca)\n",
    "    store_results(results, y_test_enc, y_pred, noise=noise_std, probs=y_probs)\n",
    "\n",
    "for radius in [1, 3, 5, 7, 9, 19]: # blur\n",
    "    for noise_std in [1, 3, 5, 10, 20, 30]:\n",
    "        combo_seed = 10000 + (radius * 100) + noise_std\n",
    "        X_blur = data_preprocessing.apply_blur(Xmat_test, radius)\n",
    "        X_combo = apply_noise(X_blur, std=noise_std, seed=combo_seed)\n",
    "        X_test_flat = X_combo.reshape(X_combo.shape[0], -1)\n",
    "        X_test_pca = pca.transform(X_test_flat)\n",
    "        y_pred = model_pca.predict(X_test_pca)\n",
    "        y_probs = model_pca.predict_proba(X_test_pca)\n",
    "        store_results(results, y_test_enc, y_pred, blur=radius, noise=noise_std, probs=y_probs)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"rf_augmented_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bdf72-d3a3-49b0-952d-0d7164058fd5",
   "metadata": {},
   "source": [
    "## Saving PCA and RF PCA Model for Shiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43a519f9-b77e-4e57-be85-74ba50623171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_pca_model.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca = RandomForestClassifier(n_estimators=100, random_state=3888)\n",
    "model_pca.fit(X_train_pca, y_train_enc)\n",
    "joblib.dump(pca, \"Base_pca.joblib\")\n",
    "joblib.dump(model_pca, \"rf_pca_model.joblib\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
